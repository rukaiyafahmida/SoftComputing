{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_1_170204004.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rukaiyafahmida/SoftComputing/blob/main/Assignment_1_170204004.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "h42yKWQd64jR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f2ef8d4-59c5-403f-a124-94b182710f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TsyEQH-MHwG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c6a4b32-240f-444b-f135-2a7509a1e5bd"
      },
      "source": [
        "!pip install torchmetrics\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import torchmetrics\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.7.2)\n",
            "Requirement already satisfied: pyDeprecate==0.3.* in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (0.3.2)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.5)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.10.0+cu111)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df0 = pd.read_csv('/content/drive/MyDrive/4.2 Rukaiya/assignment2Data/firmware/firmware.csv')\n",
        "df0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "qd7E4EwuOnsp",
        "outputId": "7bf8f7da-f6c1-4de1-e06e-f576ebfcea9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                filename       class  target  \\\n",
              "0      x86__64__lsb__unix-system-v__clang-3.8.0__O0__...     malware       1   \n",
              "1      x86__64__lsb__unix-system-v__clang-3.8.0__O0__...     malware       1   \n",
              "2      x86__64__lsb__unix-system-v__clang-3.8.0__O0__...     malware       1   \n",
              "3      x86__64__lsb__unix-system-v__clang-3.8.0__O0__...     malware       1   \n",
              "4      x86__64__lsb__unix-system-v__clang-3.8.0__O0__...     malware       1   \n",
              "...                                                  ...         ...     ...   \n",
              "38882  x86__64__lsb__unix-system-v__llvm-obfuscator-3...  benignware       0   \n",
              "38883  x86__64__lsb__unix-system-v__llvm-obfuscator-3...  benignware       0   \n",
              "38884  x86__64__lsb__unix-system-v__llvm-obfuscator-3...  benignware       0   \n",
              "38885  x86__64__lsb__unix-system-v__clang-3.9.0__O0__...  benignware       0   \n",
              "38886  x86__64__lsb__unix-system-v__llvm-obfuscator-4...  benignware       0   \n",
              "\n",
              "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  ...  pixel1016  \\\n",
              "0          85      17      34      34       0      17      17  ...          0   \n",
              "1          85      17      34      34       0      17      17  ...          0   \n",
              "2          85      17      34      34       0      17      17  ...          0   \n",
              "3          85      17      34      34       0      17      17  ...          0   \n",
              "4          85      17      34      34       0      17      17  ...          0   \n",
              "...       ...     ...     ...     ...     ...     ...     ...  ...        ...   \n",
              "38882      85      17      34      34       0      17      17  ...          0   \n",
              "38883      85      17      34      34       0      17      17  ...          0   \n",
              "38884      85      17      34      34       0      17      17  ...          0   \n",
              "38885      85      17      34      34       0      17      17  ...          0   \n",
              "38886      85      17      34      34       0      17      17  ...          0   \n",
              "\n",
              "       pixel1017  pixel1018  pixel1019  pixel1020  pixel1021  pixel1022  \\\n",
              "0              0          0          0          0          0          0   \n",
              "1             51          0          0          0         34          0   \n",
              "2              0          0          0          0          0          0   \n",
              "3             51          0          0          0         34          0   \n",
              "4              0          0          0          0          0          0   \n",
              "...          ...        ...        ...        ...        ...        ...   \n",
              "38882          0          0          0          0          0          0   \n",
              "38883          0          0          0          0          0          0   \n",
              "38884          0          0          0          0          0          0   \n",
              "38885          0          0          0          0          0          0   \n",
              "38886          0          0          0          0          0          0   \n",
              "\n",
              "       pixel1023  pixel1024  Unnamed: 1027  \n",
              "0              0          0            NaN  \n",
              "1              0          0            NaN  \n",
              "2              0          0            NaN  \n",
              "3              0          0            NaN  \n",
              "4              0          0            NaN  \n",
              "...          ...        ...            ...  \n",
              "38882          0          0            NaN  \n",
              "38883          0          0            NaN  \n",
              "38884          0          0            NaN  \n",
              "38885          0          0            NaN  \n",
              "38886          0          0            NaN  \n",
              "\n",
              "[38887 rows x 1028 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8279ed51-0c9b-4e61-8969-72c8251427d9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>class</th>\n",
              "      <th>target</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel1016</th>\n",
              "      <th>pixel1017</th>\n",
              "      <th>pixel1018</th>\n",
              "      <th>pixel1019</th>\n",
              "      <th>pixel1020</th>\n",
              "      <th>pixel1021</th>\n",
              "      <th>pixel1022</th>\n",
              "      <th>pixel1023</th>\n",
              "      <th>pixel1024</th>\n",
              "      <th>Unnamed: 1027</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>x86__64__lsb__unix-system-v__clang-3.8.0__O0__...</td>\n",
              "      <td>malware</td>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>17</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>x86__64__lsb__unix-system-v__clang-3.8.0__O0__...</td>\n",
              "      <td>malware</td>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>17</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>x86__64__lsb__unix-system-v__clang-3.8.0__O0__...</td>\n",
              "      <td>malware</td>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>17</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>x86__64__lsb__unix-system-v__clang-3.8.0__O0__...</td>\n",
              "      <td>malware</td>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>17</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>x86__64__lsb__unix-system-v__clang-3.8.0__O0__...</td>\n",
              "      <td>malware</td>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>17</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38882</th>\n",
              "      <td>x86__64__lsb__unix-system-v__llvm-obfuscator-3...</td>\n",
              "      <td>benignware</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>17</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38883</th>\n",
              "      <td>x86__64__lsb__unix-system-v__llvm-obfuscator-3...</td>\n",
              "      <td>benignware</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>17</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38884</th>\n",
              "      <td>x86__64__lsb__unix-system-v__llvm-obfuscator-3...</td>\n",
              "      <td>benignware</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>17</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38885</th>\n",
              "      <td>x86__64__lsb__unix-system-v__clang-3.9.0__O0__...</td>\n",
              "      <td>benignware</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>17</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38886</th>\n",
              "      <td>x86__64__lsb__unix-system-v__llvm-obfuscator-4...</td>\n",
              "      <td>benignware</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>17</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38887 rows × 1028 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8279ed51-0c9b-4e61-8969-72c8251427d9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8279ed51-0c9b-4e61-8969-72c8251427d9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8279ed51-0c9b-4e61-8969-72c8251427d9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBFbW1QPOo-h",
        "outputId": "b017c02e-f638-428b-884c-349439555721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38887"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " df0.iloc[[334]]  # DataFrame result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "-H4DbfM-Os4F",
        "outputId": "a4eec47a-ee44-47e1-d0e5-ca740955fabc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              filename    class  target  \\\n",
              "334  x86__64__lsb__unix-system-v__gcc-4.9.4__Os__no...  malware       1   \n",
              "\n",
              "     pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  ...  pixel1016  \\\n",
              "334      85      17      34      34       0      17      17  ...          0   \n",
              "\n",
              "     pixel1017  pixel1018  pixel1019  pixel1020  pixel1021  pixel1022  \\\n",
              "334          0          0          0          0          0          0   \n",
              "\n",
              "     pixel1023  pixel1024  Unnamed: 1027  \n",
              "334          0          0            NaN  \n",
              "\n",
              "[1 rows x 1028 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e80ae7d4-baf7-48b5-811f-aa4c58dff229\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>class</th>\n",
              "      <th>target</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel1016</th>\n",
              "      <th>pixel1017</th>\n",
              "      <th>pixel1018</th>\n",
              "      <th>pixel1019</th>\n",
              "      <th>pixel1020</th>\n",
              "      <th>pixel1021</th>\n",
              "      <th>pixel1022</th>\n",
              "      <th>pixel1023</th>\n",
              "      <th>pixel1024</th>\n",
              "      <th>Unnamed: 1027</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>x86__64__lsb__unix-system-v__gcc-4.9.4__Os__no...</td>\n",
              "      <td>malware</td>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>17</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 1028 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e80ae7d4-baf7-48b5-811f-aa4c58dff229')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e80ae7d4-baf7-48b5-811f-aa4c58dff229 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e80ae7d4-baf7-48b5-811f-aa4c58dff229');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []"
      ],
      "metadata": {
        "id": "ro1UEuP3Ozjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df0.iloc[:, 0].values\n",
        "y = df0.iloc[:, 1].values"
      ],
      "metadata": {
        "id": "1cG4HoPQO2X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame(\n",
        "    {'file_name': X,\n",
        "     'class_name': y })"
      ],
      "metadata": {
        "id": "DZs2tlqaO55y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "7ijO_zNaO7cr",
        "outputId": "3d5191ff-9f42-4e1a-f5ce-33b178971ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           file_name class_name\n",
              "0  x86__64__lsb__unix-system-v__clang-3.8.0__O0__...    malware\n",
              "1  x86__64__lsb__unix-system-v__clang-3.8.0__O0__...    malware\n",
              "2  x86__64__lsb__unix-system-v__clang-3.8.0__O0__...    malware"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63f91feb-ce90-4bfd-9e38-74807ddbdbd9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>class_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>x86__64__lsb__unix-system-v__clang-3.8.0__O0__...</td>\n",
              "      <td>malware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>x86__64__lsb__unix-system-v__clang-3.8.0__O0__...</td>\n",
              "      <td>malware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>x86__64__lsb__unix-system-v__clang-3.8.0__O0__...</td>\n",
              "      <td>malware</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63f91feb-ce90-4bfd-9e38-74807ddbdbd9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63f91feb-ce90-4bfd-9e38-74807ddbdbd9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63f91feb-ce90-4bfd-9e38-74807ddbdbd9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/4.2 Rukaiya/assignment2Data/imagery'"
      ],
      "metadata": {
        "id": "aAUZAdlXQY1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oC8RtFxN6MMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "                  transforms.Grayscale(num_output_channels=1),\n",
        "                  transforms.Resize((32, 32)), \n",
        "                  transforms.Normalize(.5, .5),\n",
        "                  transforms.ToTensor(),])"
      ],
      "metadata": {
        "id": "DpJyKueb62kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ImageFolder(data_dir, transform=transform)\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "12Q2UvJwQIJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3415711-a594-4e5f-9ded-103d5ab495e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 4482\n",
            "    Root location: /content/drive/MyDrive/4.2 Rukaiya/assignment2Data/imagery\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Grayscale(num_output_channels=1)\n",
            "               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=None)\n",
            "               Normalize(mean=0.5, std=0.5)\n",
            "               ToTensor()\n",
            "           )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = 4\n",
        "torch.manual_seed(random_seed);\n",
        "test_size = math.floor(0.2 * len(dataset))\n",
        "val_size = math.floor(0.15 * len(dataset))\n",
        "train_size = len(dataset) - val_size - test_size\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "len(train_dataset), len(val_dataset), len(test_dataset)"
      ],
      "metadata": {
        "id": "rpm1MZCOQ7zl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ded3a079-a75d-4306-f1bd-7269155ebbe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2914, 672, 896)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyper parameters\n",
        "input_size = 32*32\n",
        "hidden_size = 100\n",
        "num_classes = 4\n",
        "batch_size = 20\n",
        "num_epochs = 200\n",
        "lr = 0.001"
      ],
      "metadata": {
        "id": "_N8OEwwhRWli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "  metric = torchmetrics.Accuracy()\n",
        "  metric = metric.cuda()\n",
        "  return metric(outputs, labels)\n",
        "\n",
        "def precision(outputs, labels):\n",
        "  metric = torchmetrics.Precision(average='macro', num_classes=4)\n",
        "  metric = metric.cuda()\n",
        "  return metric(outputs, labels)\n",
        "\n",
        "def recall(outputs, labels):\n",
        "  metric = torchmetrics.Recall(average='macro', num_classes=4)\n",
        "  metric = metric.cuda()\n",
        "  return metric(outputs, labels)\n",
        "\n",
        "def f1_score(outputs, labels):\n",
        "  pr = precision(outputs, labels)\n",
        "  re = recall(outputs, labels)\n",
        "  return 2 * pr * re / (pr + re)"
      ],
      "metadata": {
        "id": "fi3CwhEhR4WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class NNet(nn.Module):\n",
        "    def __init__(self, in_size, hidden_size, out_size):\n",
        "        super().__init__()\n",
        "        self.layer_1 = nn.Linear(in_size, hidden_size)\n",
        "        self.layer_2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.layer_3 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.layer_4 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.layer_5 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.layer_6 = nn.Linear(hidden_size, out_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Flatten the image tensors\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        out = self.layer_1(x)\n",
        "        out = F.relu(out)\n",
        "        out = self.layer_2(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.layer_3(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.layer_4(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.layer_5(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.layer_6(out)\n",
        "        return out\n",
        "    \n",
        "\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  \n",
        "        loss = F.cross_entropy(out, labels) \n",
        "        return loss\n",
        "    \n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                   \n",
        "        loss = F.cross_entropy(out, labels)  \n",
        "        acc = accuracy(out, labels)           \n",
        "        prec = precision(out, labels)\n",
        "        rec = recall(out, labels)\n",
        "        f1 = f1_score(out, labels)\n",
        "        return {'val_loss':loss, 'val_acc': acc, 'val_recall': rec, 'val_precision': prec, 'val_f1': f1}\n",
        "        \n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()  \n",
        "        batch_recall = [x['val_recall'] for x in outputs]\n",
        "        epoch_recall = torch.stack(batch_recall).mean()  \n",
        "        batch_precision = [x['val_precision'] for x in outputs]\n",
        "        epoch_precision = torch.stack(batch_precision).mean()  \n",
        "        batch_f1 = [x['val_f1'] for x in outputs]\n",
        "        epoch_f1 = torch.stack(batch_f1).mean()     \n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item(), 'val_recall': epoch_recall.item(), 'val_precision': epoch_precision.item(), 'val_f1': epoch_f1.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {}, val_acc: {}, val_recall: {}, val_precision: {}, val_f1: {}\".format(epoch, result['val_loss'], result['val_acc'], result['val_recall'], result['val_precision'], result['val_f1']))"
      ],
      "metadata": {
        "id": "Tq3UT6WTRPXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "metadata": {
        "id": "VHrzdYCDRaYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "metadata": {
        "id": "YClNPfbfRcLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2716a71-f310-4a03-cfd8-18a42fd9fb3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "validation_dataloader = DataLoader(val_dataset, batch_size)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size)\n",
        "model = NNet(input_size, hidden_size, out_size=num_classes)\n",
        "\n",
        "\n",
        "# Moving the model and datasets\n",
        "to_device(model, device)\n",
        "train_dataloader = DeviceDataLoader(train_dataloader, device)\n",
        "validation_dataloader = DeviceDataLoader(validation_dataloader, device)\n",
        "test_dataloader = DeviceDataLoader(test_dataloader, device)"
      ],
      "metadata": {
        "id": "qJnPSG6XvEwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "metadata": {
        "id": "JAqe2nAtRfjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NNet(input_size, hidden_size, out_size=num_classes)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "6H6vrlJURoRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8b71a99-f221-42a8-af3e-9e2513d54bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NNet(\n",
              "  (layer_1): Linear(in_features=1024, out_features=100, bias=True)\n",
              "  (layer_2): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (layer_3): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (layer_4): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (layer_5): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (layer_6): Linear(in_features=100, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = fit(num_epochs, model, train_dataloader, lr, validation_dataloader)"
      ],
      "metadata": {
        "id": "6BFwpxx5RqDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f841d736-14ac-4509-e260-fd30f7cc8edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], val_loss: 1.3674, val_acc: 0.1426, val_recall: 0.2549, val_precision: 0.0411, val_f1: nan\n",
            "Epoch [1], val_loss: 1.3230, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [2], val_loss: 1.2835, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [3], val_loss: 1.2472, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [4], val_loss: 1.2141, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [5], val_loss: 1.1838, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [6], val_loss: 1.1564, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [7], val_loss: 1.1315, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [8], val_loss: 1.1092, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [9], val_loss: 1.0891, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [10], val_loss: 1.0713, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [11], val_loss: 1.0556, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [12], val_loss: 1.0417, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [13], val_loss: 1.0295, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [14], val_loss: 1.0189, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [15], val_loss: 1.0095, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [16], val_loss: 1.0014, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [17], val_loss: 0.9944, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [18], val_loss: 0.9882, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [19], val_loss: 0.9827, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [20], val_loss: 0.9777, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [21], val_loss: 0.9733, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [22], val_loss: 0.9693, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [23], val_loss: 0.9655, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [24], val_loss: 0.9620, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [25], val_loss: 0.9585, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [26], val_loss: 0.9550, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [27], val_loss: 0.9515, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [28], val_loss: 0.9478, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [29], val_loss: 0.9441, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [30], val_loss: 0.9402, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [31], val_loss: 0.9359, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [32], val_loss: 0.9311, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [33], val_loss: 0.9259, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [34], val_loss: 0.9200, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [35], val_loss: 0.9135, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [36], val_loss: 0.9062, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [37], val_loss: 0.8979, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [38], val_loss: 0.8881, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [39], val_loss: 0.8763, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [40], val_loss: 0.8623, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [41], val_loss: 0.8466, val_acc: 0.6627, val_recall: 0.3137, val_precision: 0.2127, val_f1: 0.2517\n",
            "Epoch [42], val_loss: 0.8290, val_acc: 0.6907, val_recall: 0.3665, val_precision: 0.3280, val_f1: 0.3402\n",
            "Epoch [43], val_loss: 0.8091, val_acc: 0.7235, val_recall: 0.4172, val_precision: 0.4179, val_f1: 0.4136\n",
            "Epoch [44], val_loss: 0.7873, val_acc: 0.7422, val_recall: 0.4615, val_precision: 0.4466, val_f1: 0.4509\n",
            "Epoch [45], val_loss: 0.7647, val_acc: 0.7554, val_recall: 0.4844, val_precision: 0.4694, val_f1: 0.4743\n",
            "Epoch [46], val_loss: 0.7429, val_acc: 0.7686, val_recall: 0.5099, val_precision: 0.4824, val_f1: 0.4936\n",
            "Epoch [47], val_loss: 0.7236, val_acc: 0.7789, val_recall: 0.5255, val_precision: 0.4852, val_f1: 0.5029\n",
            "Epoch [48], val_loss: 0.7074, val_acc: 0.7892, val_recall: 0.5408, val_precision: 0.4948, val_f1: 0.5155\n",
            "Epoch [49], val_loss: 0.6942, val_acc: 0.7922, val_recall: 0.5489, val_precision: 0.4926, val_f1: 0.5182\n",
            "Epoch [50], val_loss: 0.6834, val_acc: 0.7951, val_recall: 0.5538, val_precision: 0.4933, val_f1: 0.5210\n",
            "Epoch [51], val_loss: 0.6745, val_acc: 0.7951, val_recall: 0.5538, val_precision: 0.4933, val_f1: 0.5210\n",
            "Epoch [52], val_loss: 0.6670, val_acc: 0.7936, val_recall: 0.5483, val_precision: 0.4891, val_f1: 0.5162\n",
            "Epoch [53], val_loss: 0.6606, val_acc: 0.7936, val_recall: 0.5558, val_precision: 0.4877, val_f1: 0.5190\n",
            "Epoch [54], val_loss: 0.6551, val_acc: 0.7922, val_recall: 0.5553, val_precision: 0.4858, val_f1: 0.5177\n",
            "Epoch [55], val_loss: 0.6502, val_acc: 0.7907, val_recall: 0.5547, val_precision: 0.4808, val_f1: 0.5144\n",
            "Epoch [56], val_loss: 0.6458, val_acc: 0.7907, val_recall: 0.5547, val_precision: 0.4808, val_f1: 0.5144\n",
            "Epoch [57], val_loss: 0.6418, val_acc: 0.7907, val_recall: 0.5547, val_precision: 0.4808, val_f1: 0.5144\n",
            "Epoch [58], val_loss: 0.6383, val_acc: 0.7892, val_recall: 0.5539, val_precision: 0.4782, val_f1: 0.5125\n",
            "Epoch [59], val_loss: 0.6350, val_acc: 0.7892, val_recall: 0.5539, val_precision: 0.4782, val_f1: 0.5125\n",
            "Epoch [60], val_loss: 0.6320, val_acc: 0.7892, val_recall: 0.5539, val_precision: 0.4782, val_f1: 0.5125\n",
            "Epoch [61], val_loss: 0.6292, val_acc: 0.7892, val_recall: 0.5539, val_precision: 0.4782, val_f1: 0.5125\n",
            "Epoch [62], val_loss: 0.6266, val_acc: 0.7892, val_recall: 0.5539, val_precision: 0.4782, val_f1: 0.5125\n",
            "Epoch [63], val_loss: 0.6242, val_acc: 0.7877, val_recall: 0.5529, val_precision: 0.4763, val_f1: 0.5109\n",
            "Epoch [64], val_loss: 0.6220, val_acc: 0.7877, val_recall: 0.5529, val_precision: 0.4763, val_f1: 0.5109\n",
            "Epoch [65], val_loss: 0.6199, val_acc: 0.7877, val_recall: 0.5529, val_precision: 0.4763, val_f1: 0.5109\n",
            "Epoch [66], val_loss: 0.6179, val_acc: 0.7877, val_recall: 0.5529, val_precision: 0.4763, val_f1: 0.5109\n",
            "Epoch [67], val_loss: 0.6160, val_acc: 0.7877, val_recall: 0.5529, val_precision: 0.4763, val_f1: 0.5109\n",
            "Epoch [68], val_loss: 0.6143, val_acc: 0.7877, val_recall: 0.5529, val_precision: 0.4763, val_f1: 0.5109\n",
            "Epoch [69], val_loss: 0.6127, val_acc: 0.7877, val_recall: 0.5529, val_precision: 0.4763, val_f1: 0.5109\n",
            "Epoch [70], val_loss: 0.6111, val_acc: 0.7877, val_recall: 0.5529, val_precision: 0.4763, val_f1: 0.5109\n",
            "Epoch [71], val_loss: 0.6097, val_acc: 0.7877, val_recall: 0.5529, val_precision: 0.4763, val_f1: 0.5109\n",
            "Epoch [72], val_loss: 0.6083, val_acc: 0.7877, val_recall: 0.5529, val_precision: 0.4763, val_f1: 0.5109\n",
            "Epoch [73], val_loss: 0.6070, val_acc: 0.7877, val_recall: 0.5529, val_precision: 0.4763, val_f1: 0.5109\n",
            "Epoch [74], val_loss: 0.6058, val_acc: 0.7877, val_recall: 0.5529, val_precision: 0.4763, val_f1: 0.5109\n",
            "Epoch [75], val_loss: 0.6046, val_acc: 0.7877, val_recall: 0.5529, val_precision: 0.4763, val_f1: 0.5109\n",
            "Epoch [76], val_loss: 0.6035, val_acc: 0.7877, val_recall: 0.5529, val_precision: 0.4763, val_f1: 0.5109\n",
            "Epoch [77], val_loss: 0.6024, val_acc: 0.7877, val_recall: 0.5529, val_precision: 0.4763, val_f1: 0.5109\n",
            "Epoch [78], val_loss: 0.6014, val_acc: 0.7877, val_recall: 0.5529, val_precision: 0.4763, val_f1: 0.5109\n",
            "Epoch [79], val_loss: 0.6005, val_acc: 0.7877, val_recall: 0.5529, val_precision: 0.4763, val_f1: 0.5109\n",
            "Epoch [80], val_loss: 0.5995, val_acc: 0.7877, val_recall: 0.5529, val_precision: 0.4763, val_f1: 0.5109\n",
            "Epoch [81], val_loss: 0.5987, val_acc: 0.7877, val_recall: 0.5529, val_precision: 0.4763, val_f1: 0.5109\n",
            "Epoch [82], val_loss: 0.5978, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [83], val_loss: 0.5971, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [84], val_loss: 0.5963, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [85], val_loss: 0.5956, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [86], val_loss: 0.5949, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [87], val_loss: 0.5943, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [88], val_loss: 0.5937, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [89], val_loss: 0.5931, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [90], val_loss: 0.5925, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [91], val_loss: 0.5919, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [92], val_loss: 0.5914, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [93], val_loss: 0.5909, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [94], val_loss: 0.5904, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [95], val_loss: 0.5899, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [96], val_loss: 0.5894, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [97], val_loss: 0.5890, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [98], val_loss: 0.5886, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [99], val_loss: 0.5881, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [100], val_loss: 0.5877, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [101], val_loss: 0.5873, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [102], val_loss: 0.5870, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [103], val_loss: 0.5866, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [104], val_loss: 0.5862, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [105], val_loss: 0.5858, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [106], val_loss: 0.5855, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [107], val_loss: 0.5852, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [108], val_loss: 0.5848, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [109], val_loss: 0.5845, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [110], val_loss: 0.5842, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [111], val_loss: 0.5839, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [112], val_loss: 0.5836, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [113], val_loss: 0.5833, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [114], val_loss: 0.5830, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [115], val_loss: 0.5827, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [116], val_loss: 0.5824, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [117], val_loss: 0.5822, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [118], val_loss: 0.5819, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [119], val_loss: 0.5817, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [120], val_loss: 0.5814, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [121], val_loss: 0.5811, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [122], val_loss: 0.5809, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [123], val_loss: 0.5806, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [124], val_loss: 0.5804, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [125], val_loss: 0.5802, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [126], val_loss: 0.5800, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [127], val_loss: 0.5797, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [128], val_loss: 0.5795, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [129], val_loss: 0.5793, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [130], val_loss: 0.5790, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [131], val_loss: 0.5788, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [132], val_loss: 0.5786, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [133], val_loss: 0.5784, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [134], val_loss: 0.5782, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [135], val_loss: 0.5780, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [136], val_loss: 0.5778, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [137], val_loss: 0.5776, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [138], val_loss: 0.5774, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [139], val_loss: 0.5772, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [140], val_loss: 0.5770, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [141], val_loss: 0.5768, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [142], val_loss: 0.5766, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [143], val_loss: 0.5764, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [144], val_loss: 0.5762, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [145], val_loss: 0.5761, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [146], val_loss: 0.5759, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [147], val_loss: 0.5757, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [148], val_loss: 0.5755, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [149], val_loss: 0.5753, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [150], val_loss: 0.5752, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [151], val_loss: 0.5750, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [152], val_loss: 0.5748, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [153], val_loss: 0.5746, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [154], val_loss: 0.5744, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [155], val_loss: 0.5743, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [156], val_loss: 0.5741, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [157], val_loss: 0.5739, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [158], val_loss: 0.5737, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [159], val_loss: 0.5735, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [160], val_loss: 0.5733, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [161], val_loss: 0.5731, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [162], val_loss: 0.5730, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [163], val_loss: 0.5728, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [164], val_loss: 0.5727, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [165], val_loss: 0.5725, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [166], val_loss: 0.5723, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [167], val_loss: 0.5721, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [168], val_loss: 0.5720, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [169], val_loss: 0.5718, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [170], val_loss: 0.5716, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [171], val_loss: 0.5714, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [172], val_loss: 0.5712, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [173], val_loss: 0.5711, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [174], val_loss: 0.5709, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [175], val_loss: 0.5707, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [176], val_loss: 0.5705, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [177], val_loss: 0.5703, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [178], val_loss: 0.5701, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [179], val_loss: 0.5699, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [180], val_loss: 0.5697, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [181], val_loss: 0.5695, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [182], val_loss: 0.5693, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [183], val_loss: 0.5691, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [184], val_loss: 0.5688, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [185], val_loss: 0.5686, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [186], val_loss: 0.5684, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [187], val_loss: 0.5682, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [188], val_loss: 0.5680, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [189], val_loss: 0.5677, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [190], val_loss: 0.5675, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [191], val_loss: 0.5673, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [192], val_loss: 0.5670, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [193], val_loss: 0.5667, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [194], val_loss: 0.5665, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [195], val_loss: 0.5663, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [196], val_loss: 0.5660, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [197], val_loss: 0.5657, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [198], val_loss: 0.5654, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n",
            "Epoch [199], val_loss: 0.5650, val_acc: 0.7892, val_recall: 0.5541, val_precision: 0.4766, val_f1: 0.5117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_accuracies(history, metric, ylabel, title):\n",
        "    accuracies = [x[metric] for x in history]\n",
        "    plt.plot(accuracies)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title);"
      ],
      "metadata": {
        "id": "fuNaxDjnRs0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-b')\n",
        "    plt.plot(val_losses, '-r')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');"
      ],
      "metadata": {
        "id": "OG-6dCMGcmkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(history)"
      ],
      "metadata": {
        "id": "dFr2NLrlc5RT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "49f2074a-83a5-432d-f537-0851e1e36d24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracies(history, 'val_acc', 'Validation Accuracy', 'Validation Accuracy vs. No. of epochs')"
      ],
      "metadata": {
        "id": "3QBDe5g0Rt61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "bb9b7759-0737-43b0-9553-7766c56cd864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracies(history, 'val_f1', 'Validation F1 Score', 'Validation F1 Score vs. No. of epochs')"
      ],
      "metadata": {
        "id": "AOgdYQiDbOUN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "90ed1f1a-1aae-4f46-e302-75e0cac26046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxcZZ3v8c83nQ3IwpKAGBKSQIKAC4YIqKiMgiIKYdxAlAE3BoVBxmUGrgpekDvqjMx1rlFAZICRRXDNKAoIguKISQciGDQSAkJCAgkJSRqSXn/3j/NUc7pSVV0duqo6Xd/361WvPnv96tTp51fP85xFEYGZmVmxEY0OwMzMhiYnCDMzK8kJwszMSnKCMDOzkpwgzMysJCcIMzMryQmiiUgKSfun4cskfaGaZbfjfT4g6bbtjdOGB0kHSFoiabOkcxodD7y447oZOUHsQCT9QtJFJabPk7RG0shqtxURZ0bExYMQ0/T0T9f73hFxXUS89cVuu8R7HSWpR1Jb7vXfad7LJd0qaZ2kfi/uSftsiaRNaZ07Jc0Y7JgbTdLV6fs5LDdt/2r20SD4J+BXETE+Iv6jDu9ng8wJYsdyDfBBSSqafipwXUR0NSCmensyIsblXsen6Z3ATcBH+ttA+gV5LfBpYCIwA5gPdA9WkMoMlf+v9cCXGvC++wJLG/C+NkiGygFs1fkxsAfwhsIESbsB7wSulXSYpN9JelbSaknfkDS61IbSL8sv5cY/m9Z5UtKHi5Z9h6T706/tJyR9MTf71+nvs+kX/WslnS7pntz6r5O0SNLG9Pd1uXl3SbpY0m9TU8RtkiYNdMdExLKI+A7VFUiHAI9GxB2R2RwRP4iIx1NMLZL+l6RHUkyLJU2t8rNcIum3wPPATEkvk3S7pPWSlkl6X6mAJJ0kqbVo2j9KWpCGj5P0UIpnlaTPDGD3XAO8UtKbyrz3SyUtSDEul/Sxajcs6QRJS9Mxd5ekA9P0O4G/Ab6RjovZJdadKOk76bhbJelLklrSvNPTMfGNtK//LOkt1cRc6ftLjpb0cIp5fuEHV6pZ3Z3eb52k71W7H4atiPBrB3oB3wauzI3/PbAkDR8KHAGMBKYDfwLOzS0bwP5p+GrgS2n4WOAp4OXALsD1RcseBbyC7AfFK9OyJ6Z509OyI3PvczpwTxreHdhAVssZCbw/je+R5t8FPALMBnZK418u89mPAlb2s3/2zw7risvMBLYC/05WiI0rmv9Z4EHgAEDAq8gSczWf5XHg4DR/IvAE8KE0/mpgHXBQiZh2BjYDs3LTFgEnp+HVwBvS8G7AnCqPl6vJag/n5L6TPvuILMl/ExhLljzXAm+uYtuzgeeAY4BRZE1Ky4HRuf3x0Qrr/wi4PB1zewILgb/PHUNdwD+mbZ8EbAR27y/mct9f7n/gp8CuwLS03rFp3g3A58iO87HAkY3+f2/0q+EB+DXALwyOBJ4Fxqbx3wL/WGbZc4Ef5cbLJYiryBXK6R+/d9kS2/2/wL+n4elUThCnAguL1v8dcHoavgv4fG7eJ4BflHnfo4Ce9PkLr/cVLdNvgkjLHUHWJLWWLFlcTUoUwDJgXol1qvksF+XmnQT8pmj5y4ELy8T0XeCCNDyLLGHsnMYfJ/sxMGGAx8vVZAliTNrG2/P7CJhK1rQ2PrfOvwBXV7HtLwA35cZHAKuAo3L7o2SCAPYC2oGdctPeT9ZnUTiGngSUm78wfQcVYy73/eX+B47Mjd8EnJeGrwWuAPbZ3v/P4fZyE9MOJiLuIfsVeqKk/YDDyH7xI2m2pJ8q67DeBPwfoJrmmpeS/dIt+Gt+pqTDJf1K0lpJG4Ezq9xuYdt/LZr2V2BKbnxNbvh5YFyF7T0ZEbvmXjdVGUcfEXFvRLwvIiaTNdm9kezXI2QF0CMlVqvms+T3477A4akp41lJzwIfAF5SJqzryQpJgFOAH0fE82n83cBxwF9TM8hr+/2QORHRDlycXsWfaX1EbK7wmcrpsz8ioofs81ez7r5kNYPVuX1zOVlNomBVIYvl4nppFTGX+/4Kyh1v/0RW41iYms0+vM2aTcYJYsd0LfB3wAeBWyPiqTT9W8CfyZopJgD/i+yA789qsn+qgmlF868HFgBTI2IicFluu/2dDfMkWWGQN43sl+aQEBGLgB+SNbFBVsjtV2LRaj5Lfn88AdxdlNDGRcTHy4RyOzBZ0iFkieL6fIwRMY+sAP0x2S/fgfpPsqaVdxV9pt0lja/wmcrpsz9SW/7UKtd9gqwGMSm3byZExMG5ZaYU+gdycT1ZRczlvr+KImJNRHwsIl5KVlv7ppr8lFgniB3TtcDRwMfIOiALxgObgDZJLwPKFUTFbgJOl3SQpJ2BC4vmjyf7xbZV2emSp+TmrSVr9plZZtu3ALMlnSJppKSTgIPI2oEHjTJjgdFpfKykMWWWPVLSxyTtmcZfBpwA3JsWuRK4WNKstN1XStpjOz7LT9Pyp0oalV6vKXTkFouITuBm4F/J+jtuT/GNVnZtycS0zCayfT4gkZ3ldiHwz7lpTwD/A/xL2mevJDsT7LtVbPIm4B2S3iJpFNlZYe1pe/3Fshq4DfiapAmSRkjar6gjfU/gnLTf3gscCNxSRczlvr+KJL1X0j5pdANZsh/wfh5OnCB2QBHxGNk/yC5kv+wLPkNWeG8m68yu6iyMiPg5Wb/CnWSdjHcWLfIJ4CJJm4ELyP16TU0glwC/TU0FRxRt+xmys6w+DTxDVo1/Z0Ssqya2AdgX2MILZzFtIWuLLuVZsoTwoKQ24BdkHaZfTfMvJfuMt5EVxt8haysf0GdJTSBvBU4m+9W7BvgKWX9AOdeTJf+bo+9py6cCj6WmwzPJmqqQNC2dJVRc6yvnBrIaY977yfqSniTbDxdGxC/T9i+TdFmZz7eMrBb7/8iaPY8Hjo+Ijipj+TuyhP4QWYH8fWDv3Pzfk/XFrCM7xt6TvoOKMVPm+6sintcAv0/HxALgkxGxosrPMiypbxOfmVnjSTqdrIP7yEbH0sxcgzAzs5KcIMzMrCQ3MZmZWUmuQZiZWUlV3/1zqJs0aVJMnz690WGYme1QFi9evC5dMLqNYZMgpk+fTmtra/8LmplZL0nFdwfo5SYmMzMryQnCzMxKcoIwM7OSnCDMzKwkJwgzMyvJCcLMzEpygjAzs5KGzXUQVh8LH13PPQ+vZcyoFj70+unsPNqHkNlw5f9uq9ofV23kg9/5PR1d2TNURo4Qf/+m/ejo6mH0SFdGzYYb/1dbVTY+38nHr1vMHruMZvHnj+aImbtzzf88xr0rnuEVX7yVs667j6c3bW10mGY2iJwgrF89PcGnb17C6me38o1T5rDHuDF8+PUzeHLjVk7/z4WMHzuK2//0FCfO/y2bt3Y2OlwzGyROENavb/9mBb/809N87h0Hcui+uwHwlgP3YtruO9PVHXzntLnc8LHDWb1pK1+77S8NjtbMBov7IKxf//nbx3jDrEmc/rrpvdNaRohvfXAOG5/v5FVTdwXgtNdO55rfPcbKDVsYoWyZDxy+L0fOmtSYwM3sRXGCsIo2bulkzaatnPa66UjqM+/gl07sM/6Ztx3Ayg1bWLnheQDWP9fB7Q89xYXHH8R+e47bZtvjxozkFVMmbrNdMxsanCCsouVPtwEwq0QBX2zcmJFcedrc3vFNWzv56DWtfOEnS8uu885X7s2njpnNqJb6tHY+39HNbUvX8OCqjXV5P7N6mDF5F85/+4GDvl0nCKvo4ac2AzB7r/EDXnfC2FF89yOH88DKZ+nq2fbRtgsfXc/X73iYnz6w+kXHOVD77zmOkSNcc7HhYefRLTXZrhOEVfTw022MHTWCKbvttF3rjx45grnTdy8574iZe3DMQXux9MlNLybEAWkZAYfN2IMpu27f5zFrJk4QVtFfntrMfpPH0VKjX9sH7j2BA/eeUJNtm9mL49NcraLlT7dtV/OSme34nCCsrE1bO1m9cSv7V9FBbWbDT00ThKRjJS2TtFzSeSXmny5praQl6fXR3LzTJD2cXqfVMk4rrXAGk2sQZs2pZn0QklqA+cAxwEpgkaQFEfFQ0aLfi4izi9bdHbgQmAsEsDitu6FW8dq2/rw6O4OpmlNczWz4qWUN4jBgeUSsiIgO4EZgXpXrvg24PSLWp6RwO3BsjeK0Mu5/fAO77TyKfffYudGhmFkD1DJBTAGeyI2vTNOKvVvSA5K+L2nqANe1Grrv8Q3Mmbabr3Q2a1KN7qT+b2B6RLySrJZwzUBWlnSGpFZJrWvXrq1JgM3q2ec7eGTtc8xJN+czs+ZTywSxCpiaG98nTesVEc9ERHsavRI4tNp10/pXRMTciJg7efLkQQvc4P7HnwVgzjQnCLNmVcsEsQiYJWmGpNHAycCC/AKS9s6NngD8KQ3fCrxV0m6SdgPemqZZndz3+AZaRohXTZ3Y/8JmNizV7CymiOiSdDZZwd4CXBURSyVdBLRGxALgHEknAF3AeuD0tO56SReTJRmAiyJifa1itW0t/usGDtx7vJ85bdbEavrfHxG3ALcUTbsgN3w+cH6Zda8CrqplfFbeQ6s3cdwr9u5/QTMbthrdSW1D0JaObp59vpN9tvMGfWY2PDhB2DbWbNoKwN4TxzY4EjNrJCcI28bqjVsA2GuCE4RZM3OCsG2s2VioQbiJyayZOUHYNlanBPES1yDMmpoThG1jzcat7LrzKHaq0WMMzWzH4ARh21i9catrD2bmBGHbWrNpi89gMjMnCNvWmo1beYk7qM2anhOE9dHe1c26tg43MZmZE4T19fSm7Oa6bmIyMycI66NwFfVLnCDMmp4ThPWxeqNvs2FmGScI6+OplCD2coIwa3pOENbH2rZ2xowcwfgxfg6EWbNzgrA+1m1uZ9K4MUhqdChm1mBOENbH2rZ2Jo0b3egwzGwIcIKwPta1dTBp3JhGh2FmQ4AThPWxrq3dCcLMACcIy+npCdY/18Gk8W5iMjMnCMvZ8HwH3T3hGoSZAU4QlvPMcx0AThBmBjhBWM66zdl9mJwgzAycICxnbVuWICa7D8LMcIKwnHVtbmIysxc4QVivdW3tjGoRE3ca1ehQzGwIcIKwXus2t7PHLr7NhpllnCCs17q2dl8DYWa9apogJB0raZmk5ZLOq7DcuyWFpLlpfLqkLZKWpNdltYzTMr7Nhpnl1eyezpJagPnAMcBKYJGkBRHxUNFy44FPAr8v2sQjEXFIreKzba1ra2f2XuMbHYaZDRG1rEEcBiyPiBUR0QHcCMwrsdzFwFeArTWMxfoRETzT5ttsmNkLapkgpgBP5MZXpmm9JM0BpkbEz0qsP0PS/ZLulvSGUm8g6QxJrZJa165dO2iBN6P2rh46unt8BpOZ9aoqQUjaSdIBg/nGkkYAlwKfLjF7NTAtIl4NfAq4XtKE4oUi4oqImBsRcydPnjyY4TWdzVu7APwkOTPr1W+CkHQ8sAT4RRo/RNKCKra9CpiaG98nTSsYD7wcuEvSY8ARwAJJcyOiPSKeAYiIxcAjwOwq3tO2U1t7liDGjXWCMLNMNTWIL5L1JzwLEBFLgBlVrLcImCVphqTRwMlAb2KJiI0RMSkipkfEdOBe4ISIaJU0OXVyI2kmMAtYUf3HsoHavLUTgPFj3MRkZplqfi52RsTGoounor+VIqJL0tnArUALcFVELJV0EdAaEZVqIW8ELpLUCfQAZ0bE+ipite3UttU1CDPrq5rSYKmkU4AWSbOAc4D/qWbjEXELcEvRtAvKLHtUbvgHwA+qeQ8bHJsKfRBOEGaWVNPE9A/AwUA7cD2wETi3lkFZ/RX6INzEZGYFFX8upn6An0XE3wCfq09I1ghtqQ/CTUxmVlCxBhER3UCPpIl1iscapHCa6zif5mpmSTWlQRvwoKTbgecKEyPinJpFZXXX1t7FmJEjGD3S9280s0w1CeKH6WXD2Ob2LndQm1kf/ZYIEXFNuo6hcKHasojorG1YVm+bt3Yxfqw7qM3sBf0mCElHAdcAjwECpko6LSJ+XdvQrJ7atna6/8HM+qimRPga8NaIWAYgaTZwA3BoLQOz+mpr73KCMLM+qumRHFVIDgAR8RfAbRHDTNbE5ARhZi+opkRolXQl8N00/gGgtXYhWSNs3trlayDMrI9qSoSPA2eR3WID4DfAN2sWkTXE5q2dvtW3mfVRTYkwEvh6RFwKvVdX+8HFw0hE0Nbus5jMrK9q+iDuAHbKje8E/LI24VgjbOnspid8mw0z66uaBDE2ItoKI2l459qFZPXm22yYWSnVJIjn0rOjAZB0KLCldiFZvW32rb7NrIRqSoRzgZslPUl2odxLgJNqGpXVVe+tvp0gzCynmlttLJL0MuCANMm32hhmeh836k5qM8sp28Qk6TWSXgKQEsIc4BLga5J2r1N8Vgdt7oMwsxIq9UFcDnQASHoj8GXgWrInyl1R+9CsXja3O0GY2bYqlQgtEbE+DZ8EXFF4VrSkJbUPzeql0Ek9wU1MZpZTqQbRIqmQQN4C3Jmb55+aw0ihiWmXMS0NjsTMhpJKBf0NwN2S1pGd1vobAEn7kzUz2TDxfGcXo0eOYGSLnyZnZi8omyAi4hJJdwB7A7dFRKRZI4B/qEdwVh/tnT2McXIwsyIVm4oi4t4S0/5Su3CsETq6exgzygnCzPpyqWB0dPUw2jUIMyviUsFo7+ph9EgfCmbWl0sFo6OrmzEjfQaTmfW1XQlC0oODHYg1TodrEGZWQtlOaknvKjeL7IZ9/ZJ0LPB1oAW4MiK+XGa5dwPfB14TEa1p2vnAR4Bu4JyIuLWa97SB6+h2gjCzbVU6i+l7wHVAlJg3tr8NpyfPzQeOAVYCiyQtiIiHipYbD3wS+H1u2kHAycDBwEuBX0qaHRHd/b2vDVx7Zw9jnCDMrEilBPEA8G8R8cfiGZKOrmLbhwHLI2JFWudGYB7wUNFyFwNfAT6bmzYPuDEi2oFHJS1P2/tdFe9rA9TR3eOnyZnZNir9bDwX2FRm3t9Wse0pwBO58ZVpWq/0IKKpEfGzga6b1j9DUquk1rVr11YRkpXi01zNrJSypUJE/CYiHi8zr/XFvrGkEcClwKe3dxsRcUVEzI2IuZMnT36xITWt9q4exozyWUxm1lel50Hclhs+fzu2vQqYmhvfJ00rGA+8HLhL0mPAEcACSXOrWNcGkWsQZlZKpVIh/5P8vdux7UXALEkzJI0m63ReUJgZERsjYlJETI+I6cC9wAmpdrIAOFnSGEkzgFnAwu2IwargC+XMrJRKPZOlzl6qWkR0STobuJXsNNerImKppIuA1ohYUGHdpZJuIuvQ7gLO8hlMtdPe1e2zmMxsG5USxExJC8iueygM94qIE/rbeETcAtxSNO2CMsseVTR+CdkjTq3GOrp8mquZbatSgpiXG/63WgdijRERvlDOzEqq9DyIu+sZiDVGZ3cQgTupzWwbLhWaXEd3D4CfB2Fm23Cp0OQ6urIE4RqEmRVzqdDkehOEb/dtZkX6vQGPpNlk90naN798RLy5hnFZnbR3ZWcP+ywmMytWzR3abgYuA75NduttG0ZeqEE4QZhZX9UkiK6I+FbNI7GGaHeCMLMyqikV/lvSJyTtLWn3wqvmkVldFBKEm5jMrFg1NYjT0t/88xoCmDn44Vi9uYnJzMrpN0FExIx6BGKN0XsdhBOEmRWp5iymUcDHgTemSXcBl0dEZw3jsjpp7yycxeTTXM2sr2qamL4FjAK+mcZPTdM+WqugrH4KNQg3MZlZsWoSxGsi4lW58Tsl/aFWAVl9+UpqMyunmlKhW9J+hRFJM/H1EMOGT3M1s3KqqUF8FviVpBVkz4bYF/hQTaOyuunwaa5mVkY1ZzHdIWkWcECatCwi2msbltWLT3M1s3LKJghJb46IOyW9q2jW/pKIiB/WODarA3dSm1k5lWoQbwLuBI4vMS8AJ4hhoHCaqzupzaxYpSfKXZgGL4qIR/PzJPniuWGiPT1uVFKjQzGzIaaan40/KDHt+4MdiDVGR1cPY1x7MLMSKvVBvAw4GJhY1A8xARhb68CsPtq7evy4UTMrqVIfxAHAO4Fd6dsPsRn4WC2Dsvrp6Opx/4OZlVSpD+InwE8kvTYiflfHmKyOOrp6fAaTmZVUzYVy90s6i6y5qbdpKSI+XLOorG7au7p9oz4zK6man47/BbwEeBtwN7APWTOTDQOuQZhZOdWUDPtHxBeA5yLiGuAdwOG1DcvqpaPbCcLMSqumZCg89+FZSS8HJgJ71i4kq6f2zh7fh8nMSqqmZLhC0m7AF4AFwEPAV6vZuKRjJS2TtFzSeSXmnynpQUlLJN0j6aA0fbqkLWn6EkmXDeAz2QC4BmFm5VRzs74r0+DdDOA51JJagPnAMcBKYJGkBRHxUG6x6yPisrT8CcClwLFp3iMRcUi172fbx6e5mlk5lS6U+1SlFSPi0n62fRiwPCJWpO3dCMwjq4EUtrEpt/wuZPd4sjpyJ7WZlVOpBjE+/T0AeA1Z8xJkF80trGLbU4AncuMrKdG5nU6h/RQwGnhzbtYMSfcDm4DPR8RvSqx7BnAGwLRp06oIyYq1d/X4NFczK6nShXL/G0DSr4E5EbE5jX8R+NlgBRAR84H5kk4BPg+cBqwGpkXEM5IOBX4s6eCiGgcRcQVwBcDcuXNd+9gO7a5BmFkZ1ZQMewEdufGONK0/q4CpufF90rRybgROBIiI9oh4Jg0vBh4BZlfxnjZAHV3dPovJzEqq5krqa4GFkn6Uxk8Erq5ivUXArHRr8FXAycAp+QUkzYqIh9PoO4CH0/TJwPqI6E7PwJ4FrKjiPW2AsiYmJwgz21Y1ZzFdIunnwBvSpA9FxP1VrNcl6WzgVqAFuCoilkq6CGiNiAXA2ZKOJrvWYgNZ8xLAG4GLJHUCPcCZEbF+oB/OKosIn+ZqZmVVOotpQkRskrQ78Fh6FebtXk2BHRG3ALcUTbsgN/zJMuv9gNLPobBB1NUTRPhpcmZWWqUaxPVkt/teTN/TT5XGq74mwoam9i4/j9rMyqt0FtM7018/XnSY6kwJwn0QZlZKpSamOZVWjIj7Bj8cq6fO7ixBjHKCMLMSKjUxfa3CvKDvRW22A+ooJAj3QZhZCZWamP6mnoFY/XV2Z11L7qQ2s1KquQ6CdJvvg+j7RLlraxWU1UenaxBmVkG/CULShcBRZAniFuDtwD1kF9DZDqyjq5Ag1OBIzGwoquan43uAtwBrIuJDwKvIHhpkOzh3UptZJdWUDFsiogfokjQBeJq+91iyHZT7IMyskmr6IFol7Qp8m+yiuTbgdzWNyurCfRBmVkml6yDmkz3x7RNp0mWSfgFMiIgH6hKd1dQLp7m6D8LMtlWpBvEX4N8k7Q3cBNxQzU36bMfR2eUahJmVV7ZkiIivR8RrgTcBzwBXSfqzpAsl+dkMw0ChBuF7MZlZKf2WDBHx14j4SkS8Gng/2fMg/lTzyKzm3AdhZpX0WzJIGinpeEnXAT8HlgHvqnlkVnOdXdlZTO6DMLNSKnVSH0NWYzgOWEj2SNAzIuK5OsVmNdbbxOQahJmVUKmT+nyyZ0J8OiI21CkeqyM3MZlZJZVu1ue7tQ5zvpLazCpxydDECldSuw/CzEpxgmhihZv1uQ/CzEpxydDEOrt7GNUiJNcgzGxbThBNLEsQPgTMrDSXDk2sszucIMysLJcOTazDNQgzq8ClQxPr7OphtM9gMrMynCCaWGd3j6+BMLOyXDo0MfdBmFklNS0dJB0raZmk5ZLOKzH/TEkPSloi6R5JB+XmnZ/WWybpbbWMs1m5D8LMKqlZ6SCpBZgPvB04CHh/PgEk10fEKyLiEOCrwKVp3YOAk4GDgWOBb6bt2SDq7HYfhJmVV8ufj4cByyNiRUR0kN0Ndl5+gYjYlBvdBYg0PA+4MSLaI+JRYHnang0iXwdhZpVUupvrizUFeCI3vhI4vHghSWcBnwJGA4UbBE4B7i1ad0qJdc8AzgCYNm3aoATdTDq6nCDMrLyGlw4RMT8i9gP+Gfj8ANe9IiLmRsTcyZMn1ybAYayjO3wWk5mVVcvSYRUwNTe+T5pWzo1kjzPdnnVtO/g6CDOrpJYJYhEwS9IMSaPJOp0X5BeQNCs3+g7g4TS8ADhZ0hhJM4BZZE+1s0HkPggzq6RmfRAR0SXpbOBWoAW4KiKWSroIaI2IBcDZko4GOoENwGlp3aWSbgIeArqAsyKiu1axNisnCDOrpJad1ETELcAtRdMuyA1/ssK6lwCX1C4684VyZlaJS4cm1tHdw+iR7oMws9KcIJqYm5jMrBKXDk2s09dBmFkFLh2aWGd3MNrXQZhZGS4dmlRE+GZ9ZlaRS4cm1dWT3fbKF8qZWTlOEE2qs7sHwDUIMyvLpUOT6uzKahBOEGZWjkuHJtVRqEG4k9rMynDp0KQKTUzugzCzcpwgmpT7IMysPy4dmlRHlxOEmVXm0qFJdbgGYWb9cOnQpDq703UQvlmfmZXhBNGk3AdhZv1x6dCkOt0HYWb9cOnQpNwHYWb9cenQpHr7IJwgzKwMlw5NqrcPwp3UZlaGE0STcie1mfXHpUOTKlwo5yYmMyvHpUOTKvRBuAZhZuW4dGhSLzQxuQ/CzEpzgmhSvXdz9e2+zawMlw5NytdBmFl/XDo0KT9Rzsz649KhSXV299AyQrSMcB+EmZXmBNGkOrt73EFtZhXVNEFIOlbSMknLJZ1XYv6nJD0k6QFJd0jaNzevW9KS9FpQyzibUUd3j5uXzKyikbXasKQWYD5wDLASWCRpQUQ8lFvsfmBuRDwv6ePAV4GT0rwtEXFIreIrePb5Dt572e9q/TZDztOb250gzKyimiUI4DBgeUSsAJB0IzAP6E0QEfGr3PL3Ah+sYTwljRghZu01rt5v23Cz9hrHnGm7NToMMxvCapkgpgBP5MZXAodXWP4jwM9z42MltQJdwJcj4sfFK0g6AzgDYNq0adsV5ISxo/jmBw7drnXNzIazWiaIqkn6IDAXeFNu8r4RsUrSTOBOSQ9GxCP59SLiCuAKgLlz50bdAjYzawK1bIReBUzNje+TpvUh6Wjgc8AJEdFemB4Rq9LfFcBdwKtrGKuZmRWpZYJYBMySNEPSaOBkoEIz6jMAAAbDSURBVM/ZSJJeDVxOlhyezk3fTdKYNDwJeD25vgszM6u9mjUxRUSXpLOBW4EW4KqIWCrpIqA1IhYA/wqMA26WBPB4RJwAHAhcLqmHLIl9uejsJzMzqzFFDI+m+7lz50Zra2ujwzAz26FIWhwRc0vN84nwZmZWkhOEmZmV5ARhZmYlDZs+CElrgb9ux6qTgHWDHM5gGaqxOa6BG6qxDdW4YOjGNlTjgu2Lbd+ImFxqxrBJENtLUmu5DppGG6qxOa6BG6qxDdW4YOjGNlTjgsGPzU1MZmZWkhOEmZmV5ASR7uU0RA3V2BzXwA3V2IZqXDB0YxuqccEgx9b0fRBmZlaaaxBmZlaSE4SZmZXU1Amiv2dm1zGOqZJ+lZ7PvVTSJ9P0L0palXs293ENiO0xSQ+m929N03aXdLukh9Pfuj+aTtIBuf2yRNImSec2ap9JukrS05L+mJtWcj8p8x/puHtA0pw6x/Wvkv6c3vtHknZN06dL2pLbd5fVOa6y352k89P+WibpbbWKq0Js38vF9ZikJWl6PfdZuXKidsdZRDTli+wOs48AM4HRwB+AgxoUy97AnDQ8HvgLcBDwReAzDd5PjwGTiqZ9FTgvDZ8HfGUIfJdrgH0btc+ANwJzgD/2t5+A48ienijgCOD3dY7rrcDINPyVXFzT88s1YH+V/O7S/8IfgDHAjPR/21LP2Irmfw24oAH7rFw5UbPjrJlrEL3PzI6IDqDwzOy6i4jVEXFfGt4M/Inska1D1TzgmjR8DXBiA2MBeAvwSERsz5X0gyIifg2sL5pcbj/NA66NzL3ArpL2rldcEXFbRHSl0XvJHuZVV2X2VznzgBsjoj0iHgWWk/3/1j02Zc8leB9wQ63ev5wK5UTNjrNmThClnpnd8EJZ0nSyp+f9Pk06O1UPr2pEUw4QwG2SFit7BjjAXhGxOg2vAfZqQFx5J9P3H7bR+6yg3H4aSsfeh+n7LPgZku6XdLekNzQgnlLf3VDaX28AnoqIh3PT6r7PisqJmh1nzZwghhxJ44AfAOdGxCbgW8B+wCHAarKqbb0dGRFzgLcDZ0l6Y35mZHXZhp0rrexphScAN6dJQ2GfbaPR+6kUSZ8DuoDr0qTVwLSIeDXwKeB6SRPqGNKQ/O6KvJ++P0bqvs9KlBO9Bvs4a+YEUdUzs+tF0iiyL/26iPghQEQ8FRHdEdEDfJsaVqvLiReeDf408KMUw1OFqmr6+3T5LdTc24H7IuIpGBr7LKfcfmr4sSfpdOCdwAdSoUJqwnkmDS8ma+ufXa+YKnx3Dd9fAJJGAu8CvleYVu99VqqcoIbHWTMniH6fmV0vqV3zO8CfIuLS3PR8e+HfAn8sXrfGce0iaXxhmKxz849k++m0tNhpwE/qGVeRPr/oGr3PipTbTwuAv0tnmRwBbMw1EdScpGOBfyJ7FvzzuemTJbWk4ZnALGBFHeMq990tAE6WNEbSjBTXwnrFlXM08OeIWFmYUM99Vq6coJbHWT1634fqi6yX/y9kWf9zDYzjSLJq4QPAkvQ6Dvgv4ME0fQGwd53jmkl29sgfgKWFfQTsAdwBPAz8Eti9QfttF+AZYGJuWkP2GVmSWg10krX1fqTcfiI7q2R+Ou4eBObWOa7lZG3ThWPtsrTsu9P3vAS4Dzi+znGV/e6Az6X9tQx4e72/yzT9auDMomXruc/KlRM1O858qw0zMyupmZuYzMysAicIMzMryQnCzMxKcoIwM7OSnCDMzKwkJwizIUDSUZJ+2ug4zPKcIMzMrCQnCLMBkPRBSQvTvf8vl9QiqU3Sv6d79N8haXJa9hBJ9+qF5y4U7tO/v6RfSvqDpPsk7Zc2P07S95U9q+G6dOWsWcM4QZhVSdKBwEnA6yPiEKAb+ADZFd2tEXEwcDdwYVrlWuCfI+KVZFeyFqZfB8yPiFcBryO7aheyu3OeS3aP/5nA62v+ocwqGNnoAMx2IG8BDgUWpR/3O5HdGK2HF27g9l3gh5ImArtGxN1p+jXAzeneVlMi4kcAEbEVIG1vYaT7/Ch7Ytl04J7afyyz0pwgzKon4JqIOL/PROkLRctt7/1r2nPD3fj/0xrMTUxm1bsDeI+kPaH3WcD7kv0fvSctcwpwT0RsBDbkHiBzKnB3ZE8CWynpxLSNMZJ2ruunMKuSf6GYVSkiHpL0ebIn7I0gu9vnWcBzwGFp3tNk/RSQ3Xr5spQAVgAfStNPBS6XdFHaxnvr+DHMqua7uZq9SJLaImJco+MwG2xuYjIzs5JcgzAzs5JcgzAzs5KcIMzMrCQnCDMzK8kJwszMSnKCMDOzkv4/sb1z61C/ocYAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluating the test dataset performance\n",
        "test_history = [evaluate(model, test_dataloader)]"
      ],
      "metadata": {
        "id": "JVz10n_tRrvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_history"
      ],
      "metadata": {
        "id": "3OOX0NZAczAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c29debd-1d27-4955-88c4-386de04638d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'val_acc': 0.7866666913032532,\n",
              "  'val_f1': 0.5307966470718384,\n",
              "  'val_loss': 0.5694195628166199,\n",
              "  'val_precision': 0.5056716203689575,\n",
              "  'val_recall': 0.5628145933151245}]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 02**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p1NUTt-rQLwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "seed = 4\n",
        "num_epochs = 200\n",
        "omptimser = torch.optim.Adam\n",
        "lr = 0.001"
      ],
      "metadata": {
        "id": "EUl2-vfzuQtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "                      transforms.Resize((32, 32)), \n",
        "                      transforms.RandomRotation(20),\n",
        "                      transforms.ToTensor(),])"
      ],
      "metadata": {
        "id": "LtW-rR9s7vqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ImageFolder(data_dir, transform=transform)\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "YoHsAhKqd9Wb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02833bee-d776-4dac-a3cb-a319d2c9c91d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 4482\n",
            "    Root location: /content/drive/MyDrive/4.2 Rukaiya/assignment2Data/imagery\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=None)\n",
            "               RandomRotation(degrees=[-20.0, 20.0], interpolation=nearest, expand=False, fill=0)\n",
            "               ToTensor()\n",
            "           )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(seed);\n",
        "test_size = math.floor(0.2 * len(dataset))\n",
        "val_size = math.floor(0.15 * len(dataset))\n",
        "train_size = len(dataset) - val_size - test_size\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "len(train_dataset), len(val_dataset), len(test_dataset)"
      ],
      "metadata": {
        "id": "fxLCFWwdd9Wc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5db11534-164d-4f8d-b392-8083af6ff894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2914, 672, 896)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKnenzvbgzN-"
      },
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "validation_dataloader = DataLoader(val_dataset, batch_size)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDvRyALMjz0I"
      },
      "source": [
        "class CovNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.MaxPool2d(2, 2), #64 x 16 x 16\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            \n",
        "            nn.MaxPool2d(2, 2), #128 x 8 x 8\n",
        "            \n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            \n",
        "            nn.MaxPool2d(2, 2), #256 x 4 x 4\n",
        "          \n",
        "            nn.Flatten(), \n",
        "            nn.Linear(256*4*4, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 4))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "      \n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                 \n",
        "        loss = F.cross_entropy(out, labels) \n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    \n",
        "        out = out.to(device='cuda')\n",
        "        loss = F.cross_entropy(out, labels)   \n",
        "        labels = labels.to(device='cuda')\n",
        "        acc = accuracy(out, labels)           \n",
        "        prec = precision(out, labels)\n",
        "        rec = recall(out, labels)\n",
        "        f1 = f1_score(out, labels)\n",
        "        return {'val_loss':loss, 'val_acc': acc, 'val_recall': rec, 'val_precision': prec, 'val_f1': f1}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        batch_recall = [x['val_recall'] for x in outputs]\n",
        "        epoch_recall = torch.stack(batch_recall).mean()  \n",
        "        batch_precision = [x['val_precision'] for x in outputs]\n",
        "        epoch_precision = torch.stack(batch_precision).mean()  \n",
        "        batch_f1 = [x['val_f1'] for x in outputs]\n",
        "        epoch_f1 = torch.stack(batch_f1).mean()     \n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item(), 'val_recall': epoch_recall.item(), 'val_precision': epoch_precision.item(), 'val_f1': epoch_f1.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:}, val_acc: {:}, val_recall: {:}, val_precision: {:}, val_f1: {:}\".format(epoch, result['val_loss'], result['val_acc'], result['val_recall'], result['val_precision'], result['val_f1']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzExm2aqj44O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b42b996f-0e4f-425d-b3cc-cb973c4f0c60"
      },
      "source": [
        "model = CovNet()\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CovNet(\n",
              "  (network): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU()\n",
              "    (7): Dropout(p=0.5, inplace=False)\n",
              "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (10): ReLU()\n",
              "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): ReLU()\n",
              "    (13): Dropout(p=0.5, inplace=False)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Flatten(start_dim=1, end_dim=-1)\n",
              "    (16): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "    (17): ReLU()\n",
              "    (18): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (19): ReLU()\n",
              "    (20): Dropout(p=0.5, inplace=False)\n",
              "    (21): Linear(in_features=512, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6d5mBJMkBc_"
      },
      "source": [
        "device = get_default_device()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1lH0I3SkEWW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300f0370-6392-4041-93ef-bd743ac0fe67"
      },
      "source": [
        "train_dataloader = DeviceDataLoader(train_dataloader, device)\n",
        "validation_dataloader = DeviceDataLoader(validation_dataloader, device)\n",
        "test_dataloader = DeviceDataLoader(test_dataloader, device)\n",
        "to_device(model, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CovNet(\n",
              "  (network): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (6): ReLU()\n",
              "    (7): Dropout(p=0.5, inplace=False)\n",
              "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (10): ReLU()\n",
              "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): ReLU()\n",
              "    (13): Dropout(p=0.5, inplace=False)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Flatten(start_dim=1, end_dim=-1)\n",
              "    (16): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "    (17): ReLU()\n",
              "    (18): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (19): ReLU()\n",
              "    (20): Dropout(p=0.5, inplace=False)\n",
              "    (21): Linear(in_features=512, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MORxkuUEkHRh"
      },
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oYrMwNAkSRu"
      },
      "source": [
        "model = to_device(CovNet(), device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpiv28OtntoK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802099fe-ad60-43f0-c84f-3b8b7f0a298c"
      },
      "source": [
        "history_CovN = fit(num_epochs, lr, model, train_dataloader, validation_dataloader, omptimser)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], val_loss: 0.5987120866775513, val_acc: 0.8035714626312256, val_recall: 0.5529100894927979, val_precision: 0.49187588691711426, val_f1: 0.5204028487205505\n",
            "Epoch [1], val_loss: 0.6080060005187988, val_acc: 0.7991071343421936, val_recall: 0.5489418506622314, val_precision: 0.49086058139801025, val_f1: 0.5180191397666931\n",
            "Epoch [2], val_loss: 0.8133187890052795, val_acc: 0.800595223903656, val_recall: 0.5502645969390869, val_precision: 0.4911719262599945, val_f1: 0.5188199877738953\n",
            "Epoch [3], val_loss: 0.713884711265564, val_acc: 0.8035714626312256, val_recall: 0.5529100894927979, val_precision: 0.49187588691711426, val_f1: 0.5204028487205505\n",
            "Epoch [4], val_loss: 0.641878068447113, val_acc: 0.7991071343421936, val_recall: 0.5532633662223816, val_precision: 0.4810405671596527, val_f1: 0.5143024325370789\n",
            "Epoch [5], val_loss: 0.6010519862174988, val_acc: 0.8020833730697632, val_recall: 0.5515873432159424, val_precision: 0.49150922894477844, val_f1: 0.5196125507354736\n",
            "Epoch [6], val_loss: 0.8120517134666443, val_acc: 0.8035714626312256, val_recall: 0.5529100894927979, val_precision: 0.49187588691711426, val_f1: 0.5204028487205505\n",
            "Epoch [7], val_loss: 0.714219868183136, val_acc: 0.8035714626312256, val_recall: 0.5529100894927979, val_precision: 0.49187588691711426, val_f1: 0.5204028487205505\n",
            "Epoch [8], val_loss: 0.6130842566490173, val_acc: 0.805059552192688, val_recall: 0.5555555820465088, val_precision: 0.49232810735702515, val_f1: 0.5218586325645447\n",
            "Epoch [9], val_loss: 0.6005345582962036, val_acc: 0.8020833730697632, val_recall: 0.5523689389228821, val_precision: 0.4918025732040405, val_f1: 0.5201117396354675\n",
            "Epoch [10], val_loss: 0.532406210899353, val_acc: 0.805059552192688, val_recall: 0.5555555820465088, val_precision: 0.49232810735702515, val_f1: 0.5218586325645447\n",
            "Epoch [11], val_loss: 0.6076489686965942, val_acc: 0.8035714626312256, val_recall: 0.5550380349159241, val_precision: 0.48926395177841187, val_f1: 0.5198331475257874\n",
            "Epoch [12], val_loss: 0.5827853679656982, val_acc: 0.8035714626312256, val_recall: 0.5529100894927979, val_precision: 0.49187588691711426, val_f1: 0.5204028487205505\n",
            "Epoch [13], val_loss: 0.5356609225273132, val_acc: 0.805059552192688, val_recall: 0.5555555820465088, val_precision: 0.49232810735702515, val_f1: 0.5218586325645447\n",
            "Epoch [14], val_loss: 0.644547700881958, val_acc: 0.7991071343421936, val_recall: 0.5512675642967224, val_precision: 0.4796949326992035, val_f1: 0.512006402015686\n",
            "Epoch [15], val_loss: 0.5846403241157532, val_acc: 0.8035714626312256, val_recall: 0.5529100894927979, val_precision: 0.49187588691711426, val_f1: 0.5204028487205505\n",
            "Epoch [16], val_loss: 0.5728930830955505, val_acc: 0.805059552192688, val_recall: 0.5555555820465088, val_precision: 0.49232810735702515, val_f1: 0.5218586325645447\n",
            "Epoch [17], val_loss: 0.6562599539756775, val_acc: 0.8065476417541504, val_recall: 0.557256281375885, val_precision: 0.504544198513031, val_f1: 0.5286561250686646\n",
            "Epoch [18], val_loss: 0.540934145450592, val_acc: 0.8080357313156128, val_recall: 0.5609127283096313, val_precision: 0.5168747901916504, val_f1: 0.53620445728302\n",
            "Epoch [19], val_loss: 0.5132688283920288, val_acc: 0.8110119104385376, val_recall: 0.5733581185340881, val_precision: 0.5742747783660889, val_f1: 0.5699143409729004\n",
            "Epoch [20], val_loss: 0.45678049325942993, val_acc: 0.8125, val_recall: 0.5706160664558411, val_precision: 0.556837260723114, val_f1: 0.5604913830757141\n",
            "Epoch [21], val_loss: 0.48997125029563904, val_acc: 0.8139880895614624, val_recall: 0.5767289996147156, val_precision: 0.5946727991104126, val_f1: 0.581108808517456\n",
            "Epoch [22], val_loss: 0.43832606077194214, val_acc: 0.8154761791229248, val_recall: 0.5718915462493896, val_precision: 0.590346097946167, val_f1: 0.5766529440879822\n",
            "Epoch [23], val_loss: 0.426542192697525, val_acc: 0.8333333730697632, val_recall: 0.6257582306861877, val_precision: 0.6838657259941101, val_f1: 0.6513017416000366\n",
            "Epoch [24], val_loss: 0.43171823024749756, val_acc: 0.8377976417541504, val_recall: 0.6639746427536011, val_precision: 0.6978921294212341, val_f1: 0.679340124130249\n",
            "Epoch [25], val_loss: 0.4128042161464691, val_acc: 0.84375, val_recall: 0.6338111758232117, val_precision: 0.7082269787788391, val_f1: 0.6670103073120117\n",
            "Epoch [26], val_loss: 0.3796064257621765, val_acc: 0.8541666865348816, val_recall: 0.6547223925590515, val_precision: 0.7231631875038147, val_f1: 0.6853288412094116\n",
            "Epoch [27], val_loss: 0.4101620614528656, val_acc: 0.879464328289032, val_recall: 0.717521607875824, val_precision: 0.7596131563186646, val_f1: 0.7370321750640869\n",
            "Epoch [28], val_loss: 0.3442527651786804, val_acc: 0.8616071343421936, val_recall: 0.7044040560722351, val_precision: 0.7779854536056519, val_f1: 0.7375156283378601\n",
            "Epoch [29], val_loss: 0.34702038764953613, val_acc: 0.8690476417541504, val_recall: 0.6755578517913818, val_precision: 0.7458421587944031, val_f1: 0.7071681022644043\n",
            "Epoch [30], val_loss: 0.3383435010910034, val_acc: 0.8764880895614624, val_recall: 0.7276833653450012, val_precision: 0.8084980249404907, val_f1: 0.7640761733055115\n",
            "Epoch [31], val_loss: 0.31389087438583374, val_acc: 0.8764880895614624, val_recall: 0.7248036861419678, val_precision: 0.8159581422805786, val_f1: 0.7661730647087097\n",
            "Epoch [32], val_loss: 0.2963012456893921, val_acc: 0.8764880895614624, val_recall: 0.7081311941146851, val_precision: 0.7884015440940857, val_f1: 0.7445759177207947\n",
            "Epoch [33], val_loss: 0.28063732385635376, val_acc: 0.8973214626312256, val_recall: 0.7348984479904175, val_precision: 0.7801974415779114, val_f1: 0.7554828524589539\n",
            "Epoch [34], val_loss: 0.2640971541404724, val_acc: 0.9047619104385376, val_recall: 0.760773241519928, val_precision: 0.8321078419685364, val_f1: 0.794057309627533\n",
            "Epoch [35], val_loss: 0.27965953946113586, val_acc: 0.910714328289032, val_recall: 0.8079051971435547, val_precision: 0.8765143752098083, val_f1: 0.8398539423942566\n",
            "Epoch [36], val_loss: 0.2385229915380478, val_acc: 0.9196428656578064, val_recall: 0.8521550893783569, val_precision: 0.9272289276123047, val_f1: 0.8869121074676514\n",
            "Epoch [37], val_loss: 0.2664331793785095, val_acc: 0.9226190447807312, val_recall: 0.8373098969459534, val_precision: 0.8696879744529724, val_f1: 0.8517031073570251\n",
            "Epoch [38], val_loss: 0.24390454590320587, val_acc: 0.9032738208770752, val_recall: 0.8173519372940063, val_precision: 0.8602819442749023, val_f1: 0.8372214436531067\n",
            "Epoch [39], val_loss: 0.25829485058784485, val_acc: 0.898809552192688, val_recall: 0.7841007113456726, val_precision: 0.8888591527938843, val_f1: 0.8314987421035767\n",
            "Epoch [40], val_loss: 0.21072272956371307, val_acc: 0.9270833730697632, val_recall: 0.8689720630645752, val_precision: 0.9465179443359375, val_f1: 0.905336856842041\n",
            "Epoch [41], val_loss: 0.22004260122776031, val_acc: 0.9241071343421936, val_recall: 0.8464232087135315, val_precision: 0.9216967225074768, val_f1: 0.881575345993042\n",
            "Epoch [42], val_loss: 0.18568336963653564, val_acc: 0.941964328289032, val_recall: 0.8689211010932922, val_precision: 0.8928624391555786, val_f1: 0.8801586627960205\n",
            "Epoch [43], val_loss: 0.19458770751953125, val_acc: 0.9389880895614624, val_recall: 0.8800962567329407, val_precision: 0.9039248824119568, val_f1: 0.8911110162734985\n",
            "Epoch [44], val_loss: 0.17999717593193054, val_acc: 0.9285714626312256, val_recall: 0.8553445339202881, val_precision: 0.8923695087432861, val_f1: 0.8729199171066284\n",
            "Epoch [45], val_loss: 0.18305832147598267, val_acc: 0.9389880895614624, val_recall: 0.8426691889762878, val_precision: 0.9007899165153503, val_f1: 0.8699123859405518\n",
            "Epoch [46], val_loss: 0.17553123831748962, val_acc: 0.949404776096344, val_recall: 0.8975843191146851, val_precision: 0.9357927441596985, val_f1: 0.915459156036377\n",
            "Epoch [47], val_loss: 0.16622905433177948, val_acc: 0.9672619104385376, val_recall: 0.9150397181510925, val_precision: 0.9270955920219421, val_f1: 0.9205033779144287\n",
            "Epoch [48], val_loss: 0.1393522173166275, val_acc: 0.949404776096344, val_recall: 0.9134498238563538, val_precision: 0.9389779567718506, val_f1: 0.9253816604614258\n",
            "Epoch [49], val_loss: 0.24334239959716797, val_acc: 0.9092261791229248, val_recall: 0.8314950466156006, val_precision: 0.9264732003211975, val_f1: 0.8751925826072693\n",
            "Epoch [50], val_loss: 0.20225447416305542, val_acc: 0.9627976417541504, val_recall: 0.9326531887054443, val_precision: 0.9697844982147217, val_f1: 0.9505676031112671\n",
            "Epoch [51], val_loss: 0.1729697734117508, val_acc: 0.9508928656578064, val_recall: 0.9202934503555298, val_precision: 0.9544196724891663, val_f1: 0.9363176226615906\n",
            "Epoch [52], val_loss: 0.1708158701658249, val_acc: 0.9568452835083008, val_recall: 0.9030112624168396, val_precision: 0.9236475825309753, val_f1: 0.9129891991615295\n",
            "Epoch [53], val_loss: 0.16219906508922577, val_acc: 0.9627976417541504, val_recall: 0.9430555701255798, val_precision: 0.9415265917778015, val_f1: 0.9417639374732971\n",
            "Epoch [54], val_loss: 0.11938560009002686, val_acc: 0.9583333730697632, val_recall: 0.9167311787605286, val_precision: 0.945009171962738, val_f1: 0.9300670027732849\n",
            "Epoch [55], val_loss: 0.1132003515958786, val_acc: 0.9776785969734192, val_recall: 0.9651475548744202, val_precision: 0.9709520936012268, val_f1: 0.9678776264190674\n",
            "Epoch [56], val_loss: 0.14341497421264648, val_acc: 0.9568452835083008, val_recall: 0.9297225475311279, val_precision: 0.9601591229438782, val_f1: 0.9440258741378784\n",
            "Epoch [57], val_loss: 0.10872174799442291, val_acc: 0.973214328289032, val_recall: 0.9384435415267944, val_precision: 0.9583864212036133, val_f1: 0.9479881525039673\n",
            "Epoch [58], val_loss: 0.1154683530330658, val_acc: 0.9791666865348816, val_recall: 0.9266582131385803, val_precision: 0.9342925548553467, val_f1: 0.9301364421844482\n",
            "Epoch [59], val_loss: 0.09655624628067017, val_acc: 0.9702380895614624, val_recall: 0.9400594830513, val_precision: 0.9544368982315063, val_f1: 0.9468144178390503\n",
            "Epoch [60], val_loss: 0.11291104555130005, val_acc: 0.9761905074119568, val_recall: 0.9386348128318787, val_precision: 0.9470105171203613, val_f1: 0.9425914287567139\n",
            "Epoch [61], val_loss: 0.16174811124801636, val_acc: 0.949404776096344, val_recall: 0.8661994934082031, val_precision: 0.8990498781204224, val_f1: 0.8814069628715515\n",
            "Epoch [62], val_loss: 0.08028057962656021, val_acc: 0.9761905074119568, val_recall: 0.9686987996101379, val_precision: 0.9626237750053406, val_f1: 0.9652944207191467\n",
            "Epoch [63], val_loss: 0.0773945301771164, val_acc: 0.9717261791229248, val_recall: 0.9507369995117188, val_precision: 0.9749107360839844, val_f1: 0.9624146223068237\n",
            "Epoch [64], val_loss: 0.08413240313529968, val_acc: 0.9761905074119568, val_recall: 0.9580361843109131, val_precision: 0.9566590785980225, val_f1: 0.9571893215179443\n",
            "Epoch [65], val_loss: 0.08511102199554443, val_acc: 0.9761905074119568, val_recall: 0.9536396265029907, val_precision: 0.9769616723060608, val_f1: 0.9649142622947693\n",
            "Epoch [66], val_loss: 0.09915473312139511, val_acc: 0.9747024178504944, val_recall: 0.9590174555778503, val_precision: 0.9708554744720459, val_f1: 0.9646916389465332\n",
            "Epoch [67], val_loss: 0.08173809945583344, val_acc: 0.9821428656578064, val_recall: 0.9473481178283691, val_precision: 0.9529457092285156, val_f1: 0.9499412775039673\n",
            "Epoch [68], val_loss: 0.08362733572721481, val_acc: 0.9776785969734192, val_recall: 0.9605258703231812, val_precision: 0.9515283107757568, val_f1: 0.9557563662528992\n",
            "Epoch [69], val_loss: 0.07771646231412888, val_acc: 0.9672619104385376, val_recall: 0.9183080792427063, val_precision: 0.9478440284729004, val_f1: 0.9323869347572327\n",
            "Epoch [70], val_loss: 0.10035640001296997, val_acc: 0.9821428656578064, val_recall: 0.9652194380760193, val_precision: 0.965467095375061, val_f1: 0.9648601412773132\n",
            "Epoch [71], val_loss: 0.5100163817405701, val_acc: 0.8273809552192688, val_recall: 0.7392871379852295, val_precision: 0.7726998925209045, val_f1: 0.7539560198783875\n",
            "Epoch [72], val_loss: 0.2827823758125305, val_acc: 0.8526785969734192, val_recall: 0.648044228553772, val_precision: 0.7621719837188721, val_f1: 0.6986270546913147\n",
            "Epoch [73], val_loss: 0.13848471641540527, val_acc: 0.9657738208770752, val_recall: 0.9317699670791626, val_precision: 0.9401461482048035, val_f1: 0.9356484413146973\n",
            "Epoch [74], val_loss: 0.11469972878694534, val_acc: 0.980654776096344, val_recall: 0.9559249877929688, val_precision: 0.9603782296180725, val_f1: 0.9579266309738159\n",
            "Epoch [75], val_loss: 0.0814783126115799, val_acc: 0.9747024178504944, val_recall: 0.9348530769348145, val_precision: 0.9298577308654785, val_f1: 0.932077944278717\n",
            "Epoch [76], val_loss: 0.07232873141765594, val_acc: 0.9821428656578064, val_recall: 0.9682855606079102, val_precision: 0.9705442190170288, val_f1: 0.9689880609512329\n",
            "Epoch [77], val_loss: 0.0727442130446434, val_acc: 0.980654776096344, val_recall: 0.9580528736114502, val_precision: 0.9585006237030029, val_f1: 0.957942008972168\n",
            "Epoch [78], val_loss: 0.0678304061293602, val_acc: 0.980654776096344, val_recall: 0.9663500189781189, val_precision: 0.9691429138183594, val_f1: 0.9673036336898804\n",
            "Epoch [79], val_loss: 0.07648970186710358, val_acc: 0.9851190447807312, val_recall: 0.9620711803436279, val_precision: 0.9658309817314148, val_f1: 0.9637835621833801\n",
            "Epoch [80], val_loss: 0.0556468740105629, val_acc: 0.9880952835083008, val_recall: 0.9716647863388062, val_precision: 0.983452558517456, val_f1: 0.9773741364479065\n",
            "Epoch [81], val_loss: 0.04515991359949112, val_acc: 0.9880952835083008, val_recall: 0.9691135883331299, val_precision: 0.9624848961830139, val_f1: 0.9656223058700562\n",
            "Epoch [82], val_loss: 0.045873384922742844, val_acc: 0.9895833730697632, val_recall: 0.9871430397033691, val_precision: 0.9913873672485352, val_f1: 0.9890875220298767\n",
            "Epoch [83], val_loss: 0.051414694637060165, val_acc: 0.9910714626312256, val_recall: 0.9784202575683594, val_precision: 0.9826714992523193, val_f1: 0.9805004000663757\n",
            "Epoch [84], val_loss: 0.041493531316518784, val_acc: 0.9940476417541504, val_recall: 0.9967204928398132, val_precision: 0.9923281073570251, val_f1: 0.9944847822189331\n",
            "Epoch [85], val_loss: 0.05304151773452759, val_acc: 0.9910714626312256, val_recall: 0.9779215455055237, val_precision: 0.9818015694618225, val_f1: 0.9797595739364624\n",
            "Epoch [86], val_loss: 0.04873408004641533, val_acc: 0.9866071343421936, val_recall: 0.9522367119789124, val_precision: 0.9525420665740967, val_f1: 0.9522916078567505\n",
            "Epoch [87], val_loss: 0.04684596136212349, val_acc: 0.9895833730697632, val_recall: 0.9777578115463257, val_precision: 0.9820705652236938, val_f1: 0.9798439741134644\n",
            "Epoch [88], val_loss: 0.025957031175494194, val_acc: 0.992559552192688, val_recall: 0.9938576221466064, val_precision: 0.9925427436828613, val_f1: 0.9931411147117615\n",
            "Epoch [89], val_loss: 0.03027527779340744, val_acc: 0.992559552192688, val_recall: 0.9833343029022217, val_precision: 0.9772108197212219, val_f1: 0.9801810383796692\n",
            "Epoch [90], val_loss: 0.06676919013261795, val_acc: 0.9747024178504944, val_recall: 0.9331653118133545, val_precision: 0.9519143104553223, val_f1: 0.9421638250350952\n",
            "Epoch [91], val_loss: 0.061193160712718964, val_acc: 0.9866071343421936, val_recall: 0.9867688417434692, val_precision: 0.9824610352516174, val_f1: 0.9843447804450989\n",
            "Epoch [92], val_loss: 0.05247299000620842, val_acc: 0.9910714626312256, val_recall: 0.9783298969268799, val_precision: 0.9775668978691101, val_f1: 0.9778354167938232\n",
            "Epoch [93], val_loss: 0.03873611241579056, val_acc: 0.9880952835083008, val_recall: 0.976169764995575, val_precision: 0.9751303791999817, val_f1: 0.9755110144615173\n",
            "Epoch [94], val_loss: 0.03535372018814087, val_acc: 0.9910714626312256, val_recall: 0.9668262004852295, val_precision: 0.9680407643318176, val_f1: 0.9672301411628723\n",
            "Epoch [95], val_loss: 0.03580566868185997, val_acc: 0.9895833730697632, val_recall: 0.9703856110572815, val_precision: 0.9650033712387085, val_f1: 0.967559814453125\n",
            "Epoch [96], val_loss: 0.030463023111224174, val_acc: 0.992559552192688, val_recall: 0.9920551180839539, val_precision: 0.9937946200370789, val_f1: 0.9928527474403381\n",
            "Epoch [97], val_loss: 0.09418269991874695, val_acc: 0.9836309552192688, val_recall: 0.9577260613441467, val_precision: 0.9657542109489441, val_f1: 0.9614316821098328\n",
            "Epoch [98], val_loss: 0.12462904304265976, val_acc: 0.9821428656578064, val_recall: 0.9626895785331726, val_precision: 0.959691047668457, val_f1: 0.9610631465911865\n",
            "Epoch [99], val_loss: 0.036617375910282135, val_acc: 0.9940476417541504, val_recall: 0.9938218593597412, val_precision: 0.9934056997299194, val_f1: 0.9935962557792664\n",
            "Epoch [100], val_loss: 0.055059656500816345, val_acc: 0.9910714626312256, val_recall: 0.9652116298675537, val_precision: 0.9723891615867615, val_f1: 0.9686835408210754\n",
            "Epoch [101], val_loss: 0.04424815624952316, val_acc: 0.9895833730697632, val_recall: 0.9576173424720764, val_precision: 0.9553956985473633, val_f1: 0.9564052820205688\n",
            "Epoch [102], val_loss: 0.05155846104025841, val_acc: 0.9895833730697632, val_recall: 0.9751437902450562, val_precision: 0.9821199774742126, val_f1: 0.9785034656524658\n",
            "Epoch [103], val_loss: 0.04981180652976036, val_acc: 0.9970238208770752, val_recall: 0.9875283241271973, val_precision: 0.9855935573577881, val_f1: 0.9865481853485107\n",
            "Epoch [104], val_loss: 0.0326480008661747, val_acc: 0.9910714626312256, val_recall: 0.9790055751800537, val_precision: 0.9808496832847595, val_f1: 0.9798303246498108\n",
            "Epoch [105], val_loss: 0.03633211553096771, val_acc: 0.9940476417541504, val_recall: 0.9825512170791626, val_precision: 0.9843562841415405, val_f1: 0.9834029078483582\n",
            "Epoch [106], val_loss: 0.03144025430083275, val_acc: 0.9910714626312256, val_recall: 0.9849490523338318, val_precision: 0.9945421814918518, val_f1: 0.9895017743110657\n",
            "Epoch [107], val_loss: 0.03600811958312988, val_acc: 0.992559552192688, val_recall: 0.9892858266830444, val_precision: 0.9969218969345093, val_f1: 0.9930036664009094\n",
            "Epoch [108], val_loss: 0.026233481243252754, val_acc: 0.9985119104385376, val_recall: 0.997619092464447, val_precision: 0.9995039105415344, val_f1: 0.9985422492027283\n",
            "Epoch [109], val_loss: 0.025918399915099144, val_acc: 0.9940476417541504, val_recall: 0.981878399848938, val_precision: 0.9856776595115662, val_f1: 0.9837361574172974\n",
            "Epoch [110], val_loss: 0.016926635056734085, val_acc: 0.9970238208770752, val_recall: 0.9955140948295593, val_precision: 0.9955140948295593, val_f1: 0.9955140948295593\n",
            "Epoch [111], val_loss: 0.017938358709216118, val_acc: 0.9985119104385376, val_recall: 0.9988095760345459, val_precision: 0.9993734955787659, val_f1: 0.999089777469635\n",
            "Epoch [112], val_loss: 0.018857505172491074, val_acc: 0.9970238208770752, val_recall: 0.9964569211006165, val_precision: 0.997558057308197, val_f1: 0.9969620704650879\n",
            "Epoch [113], val_loss: 0.02023749053478241, val_acc: 0.9940476417541504, val_recall: 0.9732426404953003, val_precision: 0.9726751446723938, val_f1: 0.9729256629943848\n",
            "Epoch [114], val_loss: 0.03626367822289467, val_acc: 0.9955357313156128, val_recall: 0.9736887812614441, val_precision: 0.9726966619491577, val_f1: 0.9731295704841614\n",
            "Epoch [115], val_loss: 0.026823963969945908, val_acc: 0.9895833730697632, val_recall: 0.9646542072296143, val_precision: 0.9690828323364258, val_f1: 0.9667282104492188\n",
            "Epoch [116], val_loss: 0.013562952168285847, val_acc: 0.9985119104385376, val_recall: 0.9880952835083008, val_precision: 0.9875776171684265, val_f1: 0.9878345727920532\n",
            "Epoch [117], val_loss: 0.027152303606271744, val_acc: 0.9895833730697632, val_recall: 0.9715961217880249, val_precision: 0.9631456732749939, val_f1: 0.9671791791915894\n",
            "Epoch [118], val_loss: 0.033908091485500336, val_acc: 0.9895833730697632, val_recall: 0.9824520349502563, val_precision: 0.9751039147377014, val_f1: 0.9786286950111389\n",
            "Epoch [119], val_loss: 0.023773156106472015, val_acc: 0.9955357313156128, val_recall: 0.9837490320205688, val_precision: 0.9863258600234985, val_f1: 0.9850070476531982\n",
            "Epoch [120], val_loss: 0.01532693486660719, val_acc: 0.9985119104385376, val_recall: 0.9994588494300842, val_precision: 0.9970238208770752, val_f1: 0.9982089996337891\n",
            "Epoch [121], val_loss: 0.019527379423379898, val_acc: 0.9940476417541504, val_recall: 0.9898148775100708, val_precision: 0.9976039528846741, val_f1: 0.9936031103134155\n",
            "Epoch [122], val_loss: 0.14418242871761322, val_acc: 0.9523809552192688, val_recall: 0.9057499170303345, val_precision: 0.8878414034843445, val_f1: 0.8961975574493408\n",
            "Epoch [123], val_loss: 0.08468443900346756, val_acc: 0.9866071343421936, val_recall: 0.9811387658119202, val_precision: 0.9812259078025818, val_f1: 0.9810166358947754\n",
            "Epoch [124], val_loss: 0.06223702430725098, val_acc: 0.980654776096344, val_recall: 0.9429232478141785, val_precision: 0.9670366048812866, val_f1: 0.9545369148254395\n",
            "Epoch [125], val_loss: 0.03486432880163193, val_acc: 0.9910714626312256, val_recall: 0.9718677997589111, val_precision: 0.9664016366004944, val_f1: 0.9689424633979797\n",
            "Epoch [126], val_loss: 0.031045570969581604, val_acc: 0.9895833730697632, val_recall: 0.9899102449417114, val_precision: 0.9891636371612549, val_f1: 0.9894277453422546\n",
            "Epoch [127], val_loss: 0.024933360517024994, val_acc: 0.9940476417541504, val_recall: 0.9943783283233643, val_precision: 0.9949642419815063, val_f1: 0.9946373105049133\n",
            "Epoch [128], val_loss: 0.02980821579694748, val_acc: 0.992559552192688, val_recall: 0.9792208075523376, val_precision: 0.9810064435005188, val_f1: 0.9799668788909912\n",
            "Epoch [129], val_loss: 0.03560992702841759, val_acc: 0.9910714626312256, val_recall: 0.9837838411331177, val_precision: 0.9741120338439941, val_f1: 0.9787899255752563\n",
            "Epoch [130], val_loss: 0.03224039450287819, val_acc: 0.9910714626312256, val_recall: 0.9885004162788391, val_precision: 0.9934663772583008, val_f1: 0.990945041179657\n",
            "Epoch [131], val_loss: 0.020309967920184135, val_acc: 0.9940476417541504, val_recall: 0.9855384230613708, val_precision: 0.9817460775375366, val_f1: 0.9836066365242004\n",
            "Epoch [132], val_loss: 0.021932287141680717, val_acc: 0.9955357313156128, val_recall: 0.992647111415863, val_precision: 0.9954906702041626, val_f1: 0.9938672780990601\n",
            "Epoch [133], val_loss: 0.013861089944839478, val_acc: 0.9985119104385376, val_recall: 0.9880952835083008, val_precision: 0.9875776171684265, val_f1: 0.9878345727920532\n",
            "Epoch [134], val_loss: 0.01728469878435135, val_acc: 0.9970238208770752, val_recall: 0.9949735403060913, val_precision: 0.9988807439804077, val_f1: 0.9968857765197754\n",
            "Epoch [135], val_loss: 0.028912818059325218, val_acc: 0.9866071343421936, val_recall: 0.9600597620010376, val_precision: 0.9657551050186157, val_f1: 0.9626616835594177\n",
            "Epoch [136], val_loss: 0.01855972781777382, val_acc: 0.9955357313156128, val_recall: 0.9966553449630737, val_precision: 0.9950981140136719, val_f1: 0.9958522915840149\n",
            "Epoch [137], val_loss: 0.020789295434951782, val_acc: 0.9940476417541504, val_recall: 0.9975326657295227, val_precision: 0.9914966225624084, val_f1: 0.9944652318954468\n",
            "Epoch [138], val_loss: 0.056943923234939575, val_acc: 0.992559552192688, val_recall: 0.9970517158508301, val_precision: 0.9887136816978455, val_f1: 0.9927917122840881\n",
            "Epoch [139], val_loss: 0.014434082433581352, val_acc: 1.0, val_recall: 1.0, val_precision: 1.0, val_f1: 1.0\n",
            "Epoch [140], val_loss: 0.03150368481874466, val_acc: 0.9895833730697632, val_recall: 0.9767510890960693, val_precision: 0.976355791091919, val_f1: 0.9762042164802551\n",
            "Epoch [141], val_loss: 0.013409599661827087, val_acc: 0.9955357313156128, val_recall: 0.9966811537742615, val_precision: 0.9941060543060303, val_f1: 0.9953476190567017\n",
            "Epoch [142], val_loss: 0.014972014352679253, val_acc: 0.9970238208770752, val_recall: 0.9761905074119568, val_precision: 0.9736887812614441, val_f1: 0.9749093651771545\n",
            "Epoch [143], val_loss: 0.028652852401137352, val_acc: 0.9910714626312256, val_recall: 0.9762755036354065, val_precision: 0.9843189120292664, val_f1: 0.9801831245422363\n",
            "Epoch [144], val_loss: 0.012978295795619488, val_acc: 0.9970238208770752, val_recall: 0.9988378882408142, val_precision: 0.9965277314186096, val_f1: 0.9976677894592285\n",
            "Epoch [145], val_loss: 0.009077039547264576, val_acc: 1.0, val_recall: 1.0, val_precision: 1.0, val_f1: 1.0\n",
            "Epoch [146], val_loss: 0.013273030519485474, val_acc: 0.9940476417541504, val_recall: 0.9912036657333374, val_precision: 0.996381938457489, val_f1: 0.9937103390693665\n",
            "Epoch [147], val_loss: 0.024694766849279404, val_acc: 0.9955357313156128, val_recall: 0.9738095998764038, val_precision: 0.9731711745262146, val_f1: 0.9734413027763367\n",
            "Epoch [148], val_loss: 0.020457960665225983, val_acc: 0.9940476417541504, val_recall: 0.9974376559257507, val_precision: 0.9906463027000427, val_f1: 0.9939446449279785\n",
            "Epoch [149], val_loss: 0.011888938955962658, val_acc: 1.0, val_recall: 1.0, val_precision: 1.0, val_f1: 1.0\n",
            "Epoch [150], val_loss: 0.010483704507350922, val_acc: 0.9985119104385376, val_recall: 0.9973545074462891, val_precision: 0.9993386268615723, val_f1: 0.9983251690864563\n",
            "Epoch [151], val_loss: 0.013345398008823395, val_acc: 0.9955357313156128, val_recall: 0.9845778942108154, val_precision: 0.9839513897895813, val_f1: 0.9841972589492798\n",
            "Epoch [152], val_loss: 0.013478131964802742, val_acc: 0.9970238208770752, val_recall: 0.9875283241271973, val_precision: 0.9855935573577881, val_f1: 0.9865481853485107\n",
            "Epoch [153], val_loss: 0.01502581499516964, val_acc: 0.9985119104385376, val_recall: 0.9973545074462891, val_precision: 0.9993651509284973, val_f1: 0.9983378052711487\n",
            "Epoch [154], val_loss: 0.034030769020318985, val_acc: 0.9880952835083008, val_recall: 0.9448264837265015, val_precision: 0.9380544424057007, val_f1: 0.9412230849266052\n",
            "Epoch [155], val_loss: 0.0252846647053957, val_acc: 0.9940476417541504, val_recall: 0.983934223651886, val_precision: 0.9840928912162781, val_f1: 0.9839865565299988\n",
            "Epoch [156], val_loss: 0.019343718886375427, val_acc: 0.9940476417541504, val_recall: 0.9833133220672607, val_precision: 0.9840887188911438, val_f1: 0.9836585521697998\n",
            "Epoch [157], val_loss: 0.019579511135816574, val_acc: 0.9955357313156128, val_recall: 0.9857596755027771, val_precision: 0.9829480648040771, val_f1: 0.9842848181724548\n",
            "Epoch [158], val_loss: 0.018344324082136154, val_acc: 0.9955357313156128, val_recall: 0.9813492298126221, val_precision: 0.983234167098999, val_f1: 0.9822089076042175\n",
            "Epoch [159], val_loss: 0.004403282422572374, val_acc: 1.0, val_recall: 1.0, val_precision: 1.0, val_f1: 1.0\n",
            "Epoch [160], val_loss: 0.03400789201259613, val_acc: 0.9895833730697632, val_recall: 0.9723734259605408, val_precision: 0.9839678406715393, val_f1: 0.9779779314994812\n",
            "Epoch [161], val_loss: 0.02031564526259899, val_acc: 1.0, val_recall: 1.0, val_precision: 1.0, val_f1: 1.0\n",
            "Epoch [162], val_loss: 0.04047873988747597, val_acc: 0.9851190447807312, val_recall: 0.9638890027999878, val_precision: 0.9820651412010193, val_f1: 0.9726695418357849\n",
            "Epoch [163], val_loss: 0.01682211458683014, val_acc: 0.9955357313156128, val_recall: 0.9964187741279602, val_precision: 0.9965389966964722, val_f1: 0.9964566826820374\n",
            "Epoch [164], val_loss: 0.03159700334072113, val_acc: 0.9985119104385376, val_recall: 0.9980159401893616, val_precision: 0.9990663528442383, val_f1: 0.99853515625\n",
            "Epoch [165], val_loss: 0.020331906154751778, val_acc: 0.9955357313156128, val_recall: 0.9886905550956726, val_precision: 0.9984598755836487, val_f1: 0.9933578968048096\n",
            "Epoch [166], val_loss: 0.02205209620296955, val_acc: 0.9970238208770752, val_recall: 0.9968369007110596, val_precision: 0.9963624477386475, val_f1: 0.9965453743934631\n",
            "Epoch [167], val_loss: 0.02445395290851593, val_acc: 0.992559552192688, val_recall: 0.9759800434112549, val_precision: 0.982714056968689, val_f1: 0.979069709777832\n",
            "Epoch [168], val_loss: 0.022432265803217888, val_acc: 0.9910714626312256, val_recall: 0.9752540588378906, val_precision: 0.9805219769477844, val_f1: 0.9776927828788757\n",
            "Epoch [169], val_loss: 0.01376557257026434, val_acc: 0.9955357313156128, val_recall: 0.9735450148582458, val_precision: 0.9744704365730286, val_f1: 0.9739823341369629\n",
            "Epoch [170], val_loss: 0.01735798455774784, val_acc: 0.9940476417541504, val_recall: 0.9718442559242249, val_precision: 0.9724869728088379, val_f1: 0.9721065163612366\n",
            "Epoch [171], val_loss: 0.01262760628014803, val_acc: 0.9955357313156128, val_recall: 0.9742063879966736, val_precision: 0.9723581671714783, val_f1: 0.9732334017753601\n",
            "Epoch [172], val_loss: 0.01616947539150715, val_acc: 0.9970238208770752, val_recall: 0.997101366519928, val_precision: 0.9974747896194458, val_f1: 0.997258186340332\n",
            "Epoch [173], val_loss: 0.0263940691947937, val_acc: 0.9910714626312256, val_recall: 0.9760393500328064, val_precision: 0.9841305017471313, val_f1: 0.9799745678901672\n",
            "Epoch [174], val_loss: 0.007401219569146633, val_acc: 1.0, val_recall: 1.0, val_precision: 1.0, val_f1: 1.0\n",
            "Epoch [175], val_loss: 0.004054753575474024, val_acc: 0.9985119104385376, val_recall: 0.9880952835083008, val_precision: 0.9875776171684265, val_f1: 0.9878345727920532\n",
            "Epoch [176], val_loss: 0.010066842660307884, val_acc: 0.9985119104385376, val_recall: 0.9880952835083008, val_precision: 0.9875776171684265, val_f1: 0.9878345727920532\n",
            "Epoch [177], val_loss: 0.013916573487222195, val_acc: 0.9985119104385376, val_recall: 0.9960318207740784, val_precision: 0.9995039105415344, val_f1: 0.9977014660835266\n",
            "Epoch [178], val_loss: 0.020313359797000885, val_acc: 0.9955357313156128, val_recall: 0.9944444298744202, val_precision: 0.996978759765625, val_f1: 0.9956663250923157\n",
            "Epoch [179], val_loss: 0.020750613883137703, val_acc: 0.9940476417541504, val_recall: 0.9711251258850098, val_precision: 0.9648810029029846, val_f1: 0.9678212404251099\n",
            "Epoch [180], val_loss: 0.021075721830129623, val_acc: 0.9910714626312256, val_recall: 0.9786916375160217, val_precision: 0.9813936352729797, val_f1: 0.9799472689628601\n",
            "Epoch [181], val_loss: 0.010020413435995579, val_acc: 0.9985119104385376, val_recall: 0.9994823932647705, val_precision: 0.9970238208770752, val_f1: 0.9982202053070068\n",
            "Epoch [182], val_loss: 0.06868721544742584, val_acc: 0.9851190447807312, val_recall: 0.9778702259063721, val_precision: 0.971675455570221, val_f1: 0.974616289138794\n",
            "Epoch [183], val_loss: 0.011190766468644142, val_acc: 0.9970238208770752, val_recall: 0.9962301850318909, val_precision: 0.9973545074462891, val_f1: 0.9967554211616516\n",
            "Epoch [184], val_loss: 0.008331792429089546, val_acc: 0.9985119104385376, val_recall: 0.9880952835083008, val_precision: 0.9875776171684265, val_f1: 0.9878345727920532\n",
            "Epoch [185], val_loss: 0.008001398295164108, val_acc: 1.0, val_recall: 1.0, val_precision: 1.0, val_f1: 1.0\n",
            "Epoch [186], val_loss: 0.020453033968806267, val_acc: 0.9955357313156128, val_recall: 0.992942214012146, val_precision: 0.9982564449310303, val_f1: 0.9955428242683411\n",
            "Epoch [187], val_loss: 0.008218876086175442, val_acc: 0.9970238208770752, val_recall: 0.9964285492897034, val_precision: 0.9988323450088501, val_f1: 0.9976103901863098\n",
            "Epoch [188], val_loss: 0.010139115154743195, val_acc: 0.9970238208770752, val_recall: 0.9989826679229736, val_precision: 0.9946429133415222, val_f1: 0.9967607855796814\n",
            "Epoch [189], val_loss: 0.04390598461031914, val_acc: 0.9880952835083008, val_recall: 0.9677249789237976, val_precision: 0.984282910823822, val_f1: 0.9757169485092163\n",
            "Epoch [190], val_loss: 0.006193105597048998, val_acc: 1.0, val_recall: 1.0, val_precision: 1.0, val_f1: 1.0\n",
            "Epoch [191], val_loss: 0.0108366459608078, val_acc: 0.9955357313156128, val_recall: 0.9978951215744019, val_precision: 0.9927721619606018, val_f1: 0.9952812194824219\n",
            "Epoch [192], val_loss: 0.006731598172336817, val_acc: 1.0, val_recall: 1.0, val_precision: 1.0, val_f1: 1.0\n",
            "Epoch [193], val_loss: 0.012866630218923092, val_acc: 0.9985119104385376, val_recall: 0.9880952835083008, val_precision: 0.9875776171684265, val_f1: 0.9878345727920532\n",
            "Epoch [194], val_loss: 0.01585065945982933, val_acc: 0.9970238208770752, val_recall: 0.9854497909545898, val_precision: 0.9869163036346436, val_f1: 0.9861597418785095\n",
            "Epoch [195], val_loss: 0.025561440736055374, val_acc: 0.9955357313156128, val_recall: 0.9849735498428345, val_precision: 0.9845353364944458, val_f1: 0.9847114086151123\n",
            "Epoch [196], val_loss: 0.009374250657856464, val_acc: 1.0, val_recall: 1.0, val_precision: 1.0, val_f1: 1.0\n",
            "Epoch [197], val_loss: 0.009847823530435562, val_acc: 0.9985119104385376, val_recall: 0.9988095760345459, val_precision: 0.9993734955787659, val_f1: 0.999089777469635\n",
            "Epoch [198], val_loss: 0.005477857310324907, val_acc: 1.0, val_recall: 1.0, val_precision: 1.0, val_f1: 1.0\n",
            "Epoch [199], val_loss: 0.009348204359412193, val_acc: 0.9985119104385376, val_recall: 0.9880952835083008, val_precision: 0.9875776171684265, val_f1: 0.9878345727920532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR1XWw6HnxeQ"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "def plot_accuracies(history, metric, ylabel, title):\n",
        "    accuracies = [x[metric] for x in history]\n",
        "    plt.plot(accuracies)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Njln6hAUn-oM"
      },
      "source": [
        "plot_accuracies(history_CovN, 'val_acc', 'Validation Accuracy', 'Validation Accuracy vs. No. of epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracies(history_CovN, 'val_f1', 'Validation F1 Score', 'Validation F1 Score vs. No. of epochs')"
      ],
      "metadata": {
        "id": "7arBx9PLfxCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcNGdfTPqBtV"
      },
      "source": [
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-b')\n",
        "    plt.plot(val_losses, '-r')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJVDxPWVqEpq"
      },
      "source": [
        "plot_losses(history_CovN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_history_CovN = [evaluate(model, validation_dataloader)]"
      ],
      "metadata": {
        "id": "KA0xwZVWf9z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXfXplh2uiDX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab0a174-d83e-42bb-d414-5034b766a6dc"
      },
      "source": [
        "test_history_CovN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'val_acc': 0.9985119104385376,\n",
              "  'val_f1': 0.9982202053070068,\n",
              "  'val_loss': 0.007863505743443966,\n",
              "  'val_precision': 0.9970238208770752,\n",
              "  'val_recall': 0.9994823932647705}]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    }
  ]
}